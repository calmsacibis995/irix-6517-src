<!-- Fragment document type declaration subset:
ArborText, Inc., 1988-1997, v.4001
<!DOCTYPE SGIDOCBK PUBLIC "-//Silicon Graphics, Inc.//DTD DocBook V2.3-based Subset V1.5//EN" [
<!ENTITY bookshelf.b.w SYSTEM "online/bookshelf.b.w.gif" NDATA gif>
<!ENTITY ch02.popup SYSTEM "online/ch02.popup.gif" NDATA gif>
<!ENTITY ch02.custom SYSTEM "online/ch02.custom.gif" NDATA gif>
<!ENTITY ch02.sysmon SYSTEM "online/ch02.sysmon.gif" NDATA gif>
<!ENTITY ch10.sysstart SYSTEM "online/ch10.sysstart.gif" NDATA gif>
]>
-->
<?Pub Inc>
<chapter id="LE76497-PARENT">
<title id="LE76497-TITLE">Managing User Processes</title>
<para>Just as files can use up your available disk space, too many processes going at once can use up your available CPU time. When this happens, your system response time gets slower and slower until finally the system cannot execute any processes effectively. If you have not tuned your kernel to allow for more processes, the system refuses new processes long before it reaches a saturation point. However, due to normal variations in system usage, you may experience fluctuations in your system performance without reaching the maximum number of processes allowed by your system.</para>
<section>
<title>Monitoring User Processes </title>
<para>Not all processes require the same amount of system resources. Some processes, such as database applications working with large files, tend to be <emphasis>disk intensive</emphasis>, requiring a great deal of reading from and writing to the disk as well as a large amount of space on the disk. These activities take up CPU time. Time is also spent waiting for the hardware to perform the requested operations. Other jobs, such as compiling programs or processing large amounts of data, are <emphasis>CPU intensive</emphasis>, since they require a great number of CPU instructions to be performed. Some jobs are <emphasis>memory intensive</emphasis>, such as a process that reads a great deal of data and manipulates it in memory. Since the disk, CPU, and memory resources are limited, if you have
more than a few intensive processes running at once on your system, you may see a performance degradation.</para>
<para>As the administrator, you should be on the lookout for general trends in system usage, so you can respond to them and keep the systems running as efficiently as possible. If a system shows signs of being overloaded, and yet the total number of processes is low, your system may still be at or above reasonable capacity. The following sections show four ways to monitor your system processes.</para>
<section>
<title>Process Monitoring With top </title>
<para>The <literal>top</literal> and <literal>gr_top</literal> commands are the most convenient utilities provided with IRIX to monitor the top CPU-using processes on your system. These utilities display the top such processes dynamically, that is, if a listed process exits, it is removed from the table and the next-highest CPU-using process takes its place. <literal>gr_top</literal> graphically displays the same information as <literal>top</literal>. If you are using a non-graphics server, you cannot use <literal>gr_top</literal> locally, but you can use it if you set the display to another system on the network that does have graphics capability. For complete information on configuring and using <literal>top</literal> and <literal>gr_top</literal>, consult the <command sectionref="1">top</command>
 and <command sectionref="1">gr_top</command> reference pages. For information on resetting the display, see <comment>removed xref to &ldquo;Displaying Windows on Remote Workstations&rdquo; on page 21 &mdash; Glen</comment>.</para>
</section>
<section>
<title>Process Monitoring on an Array</title>
<para>If you are using the <indexterm id="ITch07-0"><primary>Array Services</primary></indexterm> Array Services product, also see the <link book="GS_Array" extref="48115"><citetitle>Getting Started With Array Systems</citetitle></link> and the <command sectionref="1">array</command> reference page for more information on managing processes on an <indexterm id="ITch07-1"><primary>array</primary></indexterm> array.</para>
</section>
<section>
<title>Process Monitoring With osview </title>
<para>The <literal>osview</literal> and <literal>gr_osview</literal> commands display kernel execution statistics dynamically. If you have a graphics workstation, you can use the <command sectionref="1">gr_osview</command> tool, which provides a real-time graphical display of system memory and CPU usage. <literal>osview</literal> provides the same information in ASCII format. You can configure <literal>gr_osview</literal> to display several different types of information about your system's current status. In its default configuration, <literal>gr_osview</literal> provides information on the amount of CPU time spent on user process execution, system overhead tasks, interrupts, and idle time. For complete information on <literal>osview</literal> and <literal>gr_osview</literal>, see the <command
sectionref="1">osview</command> and <command sectionref="1">gr_osview</command> reference pages.</para>
</section>
<section>
<title>Process Monitoring With sar </title>
<para>The System Activity Reporter, <literal>sar</literal>, provides essentially the same information as <literal>osview</literal>, but it represents a &ldquo;snapshot&rdquo; of the system status, not a dynamic reflection. Because <literal>sar</literal> generates a single snapshot, it is easily saved and can be compared with a similar snapshot taken at another time. You can use <literal>sar</literal> automatically with <literal>cron</literal> to get a series of system snapshots over time to help you locate chronic system bottlenecks by establishing baselines of performance for your system at times of light and heavy loads and under loads of various kinds (CPU load, network load, disk load, and so on). For complete information on <literal>sar</literal>, see <link book="IA_BakSecAcc" extref="70848"><citetitle>
IRIX Admin: Backup, Security, and Accounting</citetitle></link> and the <command sectionref="1">sar</command> reference page. For more information on using <literal>sar</literal> to monitor system activity, see <comment>removed xref that went to &ldquo;About timex, sar, and par&rdquo; on page 21 &mdash; Glen</comment>.</para>
</section>
<section>
<title>Process Monitoring With ps </title>
<para>The <literal>ps -ef</literal> command allows you to look at all the processes currently running on your system. The output of <literal>ps -ef</literal> follows the format shown in <xref linkend="LE54439-TITLE">:</para>
<table frame="topbot">
<tbltitle id="LE54439-TITLE">Output Format of the ps -ef Command</tbltitle>
<tgroup cols="8" colsep="0" rowsep="1">
<colspec colwidth="66*">
<colspec colwidth="61*">
<colspec colwidth="68*">
<colspec colwidth="43*">
<colspec colwidth="66*">
<colspec colwidth="53*">
<colspec colwidth="74*">
<colspec colwidth="55*">
<thead>
<row><entry align="left" valign="bottom"><para>Name</para></entry><entry align="left" valign="bottom"><para>PID</para></entry><entry align="left" valign="bottom"><para>PPID</para></entry><entry align="left" valign="bottom"><para>C</para></entry><entry align="left" valign="bottom"><para>Time</para></entry><entry align="left" valign="bottom"><para>TTY</para></entry><entry align="left" valign="bottom"><para>CPU Time</para></entry><entry align="left" valign="bottom"><para>Process</para></entry></row></thead>
<tbody>
<row>
<entry align="left" valign="top"><para>joe</para></entry>
<entry align="left" valign="top"><para>23328</para></entry>
<entry align="left" valign="top"><para>316</para></entry>
<entry align="left" valign="top"><para>1</para></entry>
<entry align="left" valign="top"><para>May 5</para></entry>
<entry align="left" valign="top"><para>ttyq1</para></entry>
<entry align="left" valign="top"><para>1:01</para></entry>
<entry align="left" valign="top"><para>csh</para></entry></row></tbody></tgroup></table>
<para>In this table, the process shown is for the user <emphasis>joe</emphasis>. In a real situation, each user with processes running on the system is represented. Each field in the output contains useful information.</para>
<deflist termlength="narrow">
<deflistentry>
<term>Name </term>
<listitem><para>The login name of the user who &ldquo;owns&rdquo; the process.</para>
</listitem></deflistentry>
<deflistentry>
<term>PID </term>
<listitem><para>The process identification number.</para>
</listitem></deflistentry>
<deflistentry>
<term>PPID </term>
<listitem><para>The process identification number of the parent process that spawned or forked the listed process.</para>
</listitem></deflistentry>
<deflistentry>
<term>C </term>
<listitem><para>Current execution priority. The higher this number, the lower the scheduling priority. This number is based on the recent scheduling of the process and is not a definitive indicator of its overall priority.</para>
</listitem></deflistentry>
<deflistentry>
<term>Time </term>
<listitem><para>The time when the process began executing. If it began more than 24 hours before the <literal>ps</literal> command was given, the date on which it began is displayed.</para>
</listitem></deflistentry>
<deflistentry>
<term>TTY </term>
<listitem><para>The TTY (Terminal or window) with which the process is associated.</para>
</listitem></deflistentry>
<deflistentry>
<term>CPU </term>
<listitem><para>The total amount of CPU time expended to date on this process. This field is useful in determining which processes are using the most CPU time. If a process uses a great deal in a brief period, it can cause a general system slowdown.</para>
</listitem></deflistentry>
</deflist>
<para>For even more information, including the general system priority of each process, use the <command>-l</command> flag to <literal>ps</literal>. For complete information on interpreting <literal>ps</literal> output, see the <command sectionref="1">ps</command> reference page.</para>
</section>
</section>
<section id="LE96195-PARENT">
<title id="LE96195-TITLE">Prioritizing Processes</title>
<para>IRIX provides methods for users to force their CPU-intensive processes to execute at a lower priority than general user processes. The <command sectionref="1">nice</command> and <command sectionref="1M">npri</command> commands allow the user to control the priority of their processes on the system.</para>
<section>
<title>Prioritizing Processes With nice</title>
<para>The <literal>nice</literal> command functions as follows:</para>
<literallayout><userinput>nice [ -</userinput><replaceable>increment</replaceable><userinput>&ensp;] </userinput><replaceable>command</replaceable></literallayout>
<para>When you form your command line using <literal>/bin/nice</literal>, you fill in the <replaceable>increment</replaceable> field with a number between 1 and 19. If you do not fill in a number, a default of 10 is assumed. The higher the number you use for the <replaceable>increment</replaceable>, the lower your process' priority will be (19 is the lowest possible priority; all numbers greater than 19 are interpreted as 19). The <command sectionref="1">csh</command> shell has its own internal <literal>nice</literal> functions, which operate differently from the <literal>nice</literal> command, and are documented in the <command sectionref="1">csh</command> reference page.</para>
<para>After entering the <literal>nice</literal> command and the increment on your command line, give the <replaceable>command</replaceable> as you would ordinarily enter it. For example, if the user joe wants to make his costly compile command happen at the lowest possible priority, he forms the command line as follows:</para>
<literallayout><userinput>nice -19 cc -o prog prog.c</userinput></literallayout>
<para>If a process is invoked using <literal>nice</literal>, the total amount of CPU time required to execute the program does not change, but the time is spread out, since the process executes less often.</para>
<para>The superuser (root) is the only user who can give <literal>nice</literal> a negative value and thereby <emphasis>increase</emphasis> the priority of a process. To give <literal>nice</literal> a negative value, use two minus signs before the increment. For example:</para>
<literallayout><userinput>nice --19 cc -o prog prog.c</userinput></literallayout>
<para>The above command endows that process with the highest priority a user process can have. The superuser should not use this feature frequently, as even a single process that has been upgraded in priority causes a significant system slowdown for all other users. Note that <filename>/bin/csh</filename> has a built-in <literal>nice</literal> program that uses slightly different syntax from that described here. For complete information on <literal>csh</literal>, see the <command sectionref="1">csh</command> reference page.</para>
</section>
<section>
<title>Prioritizing Processes With npri</title>
<para>The <literal>npri</literal> command allows users to make their process' priority <emphasis>nondegrading</emphasis>. In the normal flow of operations, a process loses priority as it executes, so large jobs typically use fewer CPU cycles per minute as they grow older. (There is a minimum priority, too. This priority degradation simply serves to maintain performance for simple tasks.) By using <literal>npri</literal>, the user can set the <literal>nice</literal> value of a process, make that process nondegrading, and set the default time slice that the CPU allocates to that process. <literal>npri</literal> also allows you to change the priority of a currently running process. The following example of <literal>npri</literal> sets all the possible variables for a command:</para>
<literallayout><userinput>npri -h 10 -n 10 -t 3 cc -o prog prog.c</userinput></literallayout>
<para>In this example, the <command>-h</command> flag sets the nondegrading priority of the process, while the <command>-n</command> flag sets the absolute <literal>nice</literal> priority. The <command>-t</command> flag sets the time slice allocated to the process. IRIX uses a 10-millisecond time slice as the default, so the example above sets the time slice to 30 milliseconds. For complete information about <literal>npri</literal> and its flags and options, see the <command sectionref="1">npri</command> reference page.</para>
</section>
<section id="LE45478-PARENT">
<title id="LE45478-TITLE">Changing the Priority of a Running Process</title>
<para>The superuser can change the priority of a running process with the <command sectionref="1M">renice</command> or <literal>npri</literal> commands. Only the superuser can use these commands. <literal>renice</literal> is used as follows:</para>
<literallayout><userinput>renice -n </userinput><replaceable>increment</replaceable><replaceable>&ensp;pid</replaceable><userinput>&ensp;[-u </userinput><replaceable>user</replaceable><userinput>] [-g </userinput><replaceable>pgrp</replaceable><userinput>]</userinput></literallayout>
<para>In the most commonly used form, <literal>renice</literal> is invoked on a specific process that is using system time at an overwhelming rate. However, you can also invoke it with the <command>-u</command> flag to lower the priority of all processes associated with a certain user, or with the <command>-g</command> flag to lower the priorities of all processes associated with a process group. More options exist and are documented in the <command sectionref="1M">renice</command> reference page.</para>
<para>The <literal>npri</literal> command can also be used to change the parameters of a running process. This example changes the parameters of a running process with <literal>npri</literal>:</para>
<literallayout><userinput>npri -h 10 -n 10 -t 3 -p 11962</userinput></literallayout>
<para>The superuser can use <literal>renice</literal> or <literal>npri</literal> to increase the priority of a process or user, but this can have a severe impact on system performance.</para>
</section>
</section>
<section>
<title>Terminating Processes</title>
<para>From time to time a process may use so much memory, disk, or CPU time that your only alternative is to terminate it before it causes a system crash. Before you kill a process, make sure that the user who invoked the process does not try to invoke it again. You should, if at all possible, speak to the user before killing the process, and at a minimum notify the user that the process was prematurely terminated and give a reason for the termination. If you do this, the user can reinvoke the process at a lower priority or possibly use the system's job processing facilities (<literal>at</literal>, <literal>batch</literal>, and <literal>cron</literal>) to execute the process at another time.</para>
<section>
<title>Terminating Processes With the kill Command</title>
<para>To terminate a process, use the <literal>kill</literal> command. For most terminations, use the <literal>kill</literal> -15 variation. The <command>-15</command> flag indicates that the process is to be allowed time to exit gracefully, closing any open files and descriptors. The <command>-9</command> flag to <literal>kill</literal> terminates the process immediately, with no provision for cleanup. If the process you are going to kill has any child processes executing, using the <literal>kill -9</literal> command may cause those child processes to continue to exist on the process table, though they will not be responsive to input. The <command sectionref="1">wait</command> command, given with the process number of the child process, removes them. For complete information about the syntax
and usage of the <literal>kill</literal> command, see the <command sectionref="1">kill</command> reference page. You must always know the PID of the process you intend to kill with the <literal>kill</literal> command.</para>
</section>
<section>
<title>Killing Processes by Name With the killall Command</title>
<para>The <literal>killall</literal> command allows you to kill processes by their command name. For example, if you wish to kill the program <literal>a.out</literal> that you invoked, use the syntax:</para>
<literallayout><userinput>killall a.out</userinput></literallayout>
<para>This command allows you to kill processes without the time-consuming task of looking up the process ID number with the <literal>ps</literal> command.</para>
<note><para>This command kills all instances of the named program running under your shell and if invoked with no arguments, kills all processes on the system that are killable by the user who invoked the command. For ordinary users, these are simply the processes invoked and forked by that user, but if invoked by root, all processes on the system are killed. For this reason, this command should be used carefully. For more information on <literal>killall</literal>, refer to the <command sectionref="1M">killall</command> reference page.</para>
</note>
</section>
</section>
<section id="LE73554-PARENT">
<title id="LE73554-TITLE">Scheduling Processes With the Miser Batch Processing System</title>
<para><indexterm id="ITch07-2"><primary>Miser</primary><secondary>overview</secondary></indexterm>Miser is a resource management facility that provides deterministic batch scheduling of applications with known time and space requirements without requiring static partitioning of system resources. When Miser is given a job, it searches through the time/space pool that it manages to find an allocation that best fits the job's resource requirements.</para>
<para>Miser has an extensive administrative interface that allows most parameters to be modified without requiring a restart. Miser runs as a separate trusted process. All communication to Miser, either from the kernel or the user, is done through a series of Miser commands. Miser accepts requests for process scheduling, process state changes, and batch system configuration control, and returns values and status information for those requests.</para>
<section>
<title>Miser Overview</title>
<para><indexterm id="ITch07-3"><primary>Miser</primary><secondary>pools</secondary></indexterm>Miser manages a set of time/space pools. The time component of the pool defines how far into the future Miser can schedule jobs. The space component of the pool is the set of resources against which a job can be scheduled. This component can vary with time.</para>
<para><indexterm id="ITch07-4"><primary>Miser</primary><secondary>system pool</secondary></indexterm>A system pool represents the set of resources (number of CPUs and physical memory) that is available to Miser. A set of user-defined pools represents resources against which jobs can be scheduled. The resources owned by the user pools cannot exceed the total resources available to Miser. Resources managed by Miser are available to non-Miser applications when they are unused by a scheduled job.</para>
<para>Associated with each pool is a definition of the pool resources, a set of jobs allocating resources from the pool, and a policy that controls the scheduling of jobs. The collection of the resource pool, jobs scheduled, and policy is called a <indexterm id="ITch07-5"><primary>Miser</primary><secondary>queue</secondary></indexterm><emphasis>queue</emphasis>.</para>
<para>The queues allow for fine-grained resource management of the batch system. The resources allotted to a queue can vary with time. For example, a queue can be configured to manage 5 CPUs during the day and 20 during the night. The use of multiple queues allows the resources to be partitioned among different users of a batch system. For example, on a 24 CPU system, it is possible to define two queues: one that has 16 CPUs and another that has 6 CPUs (assuming that 2 CPUs have been kept outside the control of Miser). It is possible to restrict access to queues to particular users or groups of users on a system to enforce this resource partition.</para>
<para>The policy defines the way a block of time/space is searched to satisfy the resource request made by the application. Miser has two policies: &ldquo;default&rdquo; and &ldquo;repack.&rdquo; Default is the first fit policy. Once a job is scheduled, its start and end time remain constant. If an earlier job finishes ahead of schedule, it does not have an effect on the start/end time of future scheduled jobs. On the other hand, in addition to using the first fit policy, repack maintains the order of the scheduled jobs and attempts to reschedule the jobs to pull them ahead in time in the event of a job's early termination.</para>
<para>Users submit jobs to the queue using the <literal>miser_submit</literal> command, which specifies the queue to which the job should be attached and a resource request to be made against the queue. Each Miser job is an IRIX process group. The resource request is a tuple of time and space. The time is the total CPU wall-clock time if run on a single CPU. The space is the logical number of CPUs and the physical memory required. The request is passed to Miser, and Miser schedules the job against the queue's resources using the policy attached to the queue. Miser returns a start and end time for the job to the user.</para>
<para>When a job's start time has not yet arrived, the job is in batch state. A job in batch state has lower priority than any non-weightless process. A job in batch state may execute if the system has idle resources; it is said to run opportunistically. When the specified execution time arrives, the job state is changed to batch critical, and the job then has priority over any non-realtime process. The time spent executing in batch state does not count against the time that has been requested and scheduled. While the process is in batch critical state, it is guaranteed the physical memory and CPUs that it requested. The process is terminated if it exceeds its time allotment or uses more physical memory than it had requested.</para>
<para>A job with the static flag specified that was scheduled with the default policy will only run when the segment is scheduled to run. It will not run earlier even if idle resources are available to the job. If a job is scheduled with the repack policy, it may run earlier.</para>
<section>
<title>About Logical Number of CPUs</title>
<para><indexterm id="ITch07-6"><primary>Miser</primary><secondary>logical number of CPUs</secondary></indexterm> <indexterm id="ITch07-7"><primary>Miser</primary><secondary>CPU allocation</secondary></indexterm>When a job is scheduled by Miser, it requests that a number of CPUs and some amount of memory be reserved for use by the job. When the time period during which these resources were reserved for the job arrives, Miser reserves specific CPUs and some amount of logical swap space for the job.</para>
<para>There are a number of issues that affect CPU allocation for a job. When a job becomes batch critical, Miser will try to find a dense cluster of nodes. If it fails to find such a cluster, it will assign the threads of the job to any free CPUs that are available. These CPUs may be located at distant parts of the system.</para>
</section>
<section>
<title>The Effect of Reservation of CPUs on Interactive Processes</title>
<para>The way in which Miser handles the reservation of CPUs is one of its strengths. Miser controls and reserves CPUs based on a logical number, not on physical CPUs. This provides Miser with flexibility in how it controls CPU resources.</para>
<para>Interactive and batch processes that run opportunistically are allowed to use all CPUs in a system that have not been reserved for Miser jobs. If new jobs are submitted, Miser attempts to schedule the jobs based on the amount of logical resources still available to Miser. As a result, CPUs could become reserved by Miser, and the interactive processes would no longer be able to execute on the newly reserved CPUs. However, if a resource is not being used by Miser, the resource is free to be used by any other application. Miser will claim the resource when it needs it.</para>
</section>
<section>
<title>About Miser Memory Management</title>
<para><indexterm id="ITch07-8"><primary>Miser</primary><secondary>memory management</secondary></indexterm>While Miser only reserves CPUs when they are needed, memory must be reserved before it is needed.</para>
<para>When Miser is started, it is told the number of CPUs and amount of memory that it will be able to reserve for use by jobs. The number of CPUs is a logical number. When a Miser job becomes batch critical, it is assigned a set of CPUs. Until a Miser job requires a CPU (in other words, until a process or thread is ready to run), the CPU is available to the rest of the system. When a Miser job's thread begins executing, the currently non-Miser thread is preempted and resumes on a CPU where no Miser thread is currently running.</para>
<para>Memory resources are quite different than CPU resources. The memory that Miser uses to reserve for jobs is called <indexterm id="ITch07-9"><primary>Miser</primary><secondary>logical swap space</secondary></indexterm><emphasis>logical swap space</emphasis>. Logical swap space is defined as the sum total of physical memory (less space occupied by the kernel) and all the swap devices.</para>
<para>When Miser begins, it needs to reserve memory for its jobs. However, it does not need to reserve physical memory; it simply needs to make sure that there is enough physical memory plus swap to move non-Miser jobs memory to. Miser does this by reserving logical swap equal to the memory that it requires.</para>
<para>Only jobs that are submitted to Miser are able to use allocations of the logical swap space that was reserved for Miser. However, any physical memory that is not being used by Miser is free to be used by any other application. Miser will claim the physical memory when it needs it.</para>
</section>
<section>
<title>How Miser Management Affects Users</title>
<para>If a user submits a job to Miser, that job will have an allocation of resources reserved for the requested time period. The job will not have to compete for system resources. As a result, the job should complete more quickly and have more stable run-times than it would if run as an interactive job. However, there is a cost. Because Miser is space sharing the resources, the job must wait until its scheduled reservation period before the requested resources will be reserved. Prior to that time, the non-static job may run opportunistically, competing with the interactive workload, but at a lower priority than the interactive workload.</para>
<para>If a user is working interactively, the user will not have full access to all of the system resources. The user's interactive processes will have access to all of the unreserved CPUs on the system, but the processes will only have a limited amount of logical swap space available for memory allocation. The amount of logical swap space available for non-Miser jobs is the amount not reserved by Miser when it was started.</para>
</section>
</section>
<section>
<title>Miser Configuration</title>
<para><indexterm id="ITch07-10"><primary>Miser</primary><secondary>configuration</secondary></indexterm>The central configurable aspect of Miser is the set of queues. The Miser queues define the resources allocated to Miser.</para>
<para>The configuration of Miser consists of the following:</para>
<itemizedlist>
<listitem><para>Set up the Miser system queue definition file. Every Miser system must have a Miser system queue definition file. This file's vector definition specifies the maximum resources available to any other queue's vector definition.</para>
</listitem>
<listitem><para>Define the queues by setting up the Miser user queue definition file.</para>
</listitem>
<listitem><para>Enumerate all the queues that will be part of the Miser system by setting up the Miser configuration file.</para>
</listitem>
<listitem><para>Set up the Miser command-line options file to define the maximum CPUs and memory that can be managed by Miser.</para>
</listitem></itemizedlist>
<section>
<title>Setting Up the Miser System Queue Definition File</title>
<para><indexterm id="ITch07-11"><primary>Miser</primary><secondary>system queue definition file setup</secondary></indexterm>The Miser system queue definition file (<filename>/etc/miser_system.conf</filename>) defines the resources managed by the system pool. This file defines the maximum duration of the pool. All other queues must be less than or equal to the system queue. The system queue identifies the maximum limit for resources that a job can request. It is required that a Miser system queue be configured.</para>
<para>Valid tokens are as follows:</para>
<deflist>
<deflistentry>
<term>POLICY <replaceable>name</replaceable></term>
<listitem><para>The policy is always &ldquo;none&rdquo; as the system queue has no policy.</para>
</listitem></deflistentry>
<deflistentry>
<term>QUANTUM <replaceable>time</replaceable></term>
<listitem><para>The size of the quantum. A <emphasis>quantum</emphasis> is the Miser term for an arbitrary number of seconds. The quantum is used to specify how you want to break up the time/space pool. It is specified in both the system queue definition file and in the user queue definition file and must be the same in both files.</para>
</listitem></deflistentry>
<deflistentry>
<term>NSEG<replaceable>number</replaceable></term>
<listitem><para>The number of resource segments.</para>
</listitem></deflistentry>
<deflistentry>
<term>SEGMENT</term>
<listitem><para>Defines the beginning of a new segment of the vector definition. Each new segment must begin with the <replaceable>SEGMENT</replaceable> token. Each segment must contain at a minimum the number of CPUs, memory, and wall-clock time.</para>
</listitem></deflistentry>
<deflistentry>
<term>START <replaceable>number</replaceable></term>
<listitem><para>The number of quanta from 0 that the segment begins at. The origin for time is 00:00 Thursday, January 1st 1970 local time.</para>
<para>Miser maps the start and end times to the current time by repeating the queue forward until the current day. For example, a 24-hour queue always begins at midnight of the current day.</para>
</listitem></deflistentry>
<deflistentry>
<term>END <replaceable>number</replaceable></term>
<listitem><para>The number of quanta from 0 that the segment ends at.</para>
</listitem></deflistentry>
<deflistentry>
<term>NCPUS <replaceable>number</replaceable></term>
<listitem><para>The number of CPUs.</para>
</listitem></deflistentry>
<deflistentry>
<term>MEMORY <replaceable>amount</replaceable></term>
<listitem><para>The amount of memory, specified by an integer followed by an optional unit of k for kilobytes, m for megabytes, or g for gigabytes. If no unit is specified, the default is bytes.</para>
</listitem></deflistentry>
</deflist>
<para>The following system queue definition file defines a queue that has a quantum of 20 seconds and 1 element in the vector definition. The start and end times of each multiple are specified in quanta, not in seconds.</para>
<para>The segment defines a resource multiple beginning at 00:00 and ending at 00:20, with 1 CPU and 5 megabytes of memory.</para>
<programlisting>POLICY none # System queue has no policy
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 1
&nbsp;
SEGMENT
START 0
END 60# Number of quanta (20min*60sec) / 20
NCPUS 1
MEMORY 5m</programlisting>
</section>
<section>
<title>Setting Up the Miser User Queue Definition FIle</title>
<para><indexterm id="ITch07-12"><primary>Miser</primary><secondary>user queue definition file setup</secondary></indexterm>The Miser user queue definition file (<filename>/etc/miser_default.conf</filename>) defines the CPUs, the physical memory, the policy name, and the resource pool of the queue. The file consists of a header that specifies the policy of the queue, the number of resource segments, and the quantum used by the queue.</para>
<para>Access to a queue is controlled by the file permissions of the queue definition file. Read permission allows a user to examine the contents of the queue using the <literal>miser_qinfo</literal> command. Execute permission allows a user to schedule a job on a queue using the <literal>miser_submit</literal> command. Write permission allows a user to modify the resources of a queue using the <literal>miser_move</literal> and <literal>miser_reset</literal> commands.</para>
<para>The default user queue definition file can be used as a template for other user queue definition files. Each Miser queue has a separate queue definition file, which is named in the overall Miser configuration file (<filename>/etc/miser.conf</filename>	).</para>
<para>Users schedule against the resources managed by the user queues, not against the system queue. If the duration specified by a user queue is less than that specified by the system queue, the user queue will be repeated again and again (for example, the system queue specifies one week and the user queue specifies 24 hours). If the user queue does not divide into the system queue (for example, the system queue is 6 and the user queue is&nbsp;5), the user queue will repeat evenly.</para>
<para>Valid tokens are as follows:</para>
<deflist>
<deflistentry>
<term>POLICY <replaceable>name</replaceable></term>
<listitem><para>The name of the policy that will be used to schedule applications submitted to the queue. The two valid policies are &ldquo;default&rdquo; and repack.&rdquo; Default is the first fit policy; it specifies that once a job is scheduled, its start and end time remain constant. Repack maintains the order of the scheduled jobs and attempts to reschedule the jobs to pull them ahead in time in the event of a job's early termination. Note that both policies initially use the first fit method when scheduling a job.</para>
</listitem></deflistentry>
<deflistentry>
<term>QUANTUM <replaceable>time</replaceable></term>
<listitem><para>The size of the quantum. A <emphasis>quantum</emphasis> is the Miser term for an arbitrary number of seconds. The quantum is used to specify how you want to break up the time/space pool. It is specified in both the system queue definition file and in the user queue definition file and must be the same in both files.</para>
</listitem></deflistentry>
<deflistentry>
<term>NSEG <replaceable>number</replaceable></term>
<listitem><para>The number of resource segments.</para>
</listitem></deflistentry>
<deflistentry>
<term>SEGMENT</term>
<listitem><para>Defines the beginning of a new segment of the vector definition. Each new segment must begin with the <replaceable>SEGMENT</replaceable> token. Each segment must contain at a minimum the number of CPUs, memory, and wall-clock time.</para>
</listitem></deflistentry>
<deflistentry>
<term>START <replaceable>number</replaceable></term>
<listitem><para>The number of quanta from 0 that the segment begins at. The origin for time is 00:00 Thursday, January 1st 1970 local time.</para>
<para>Miser maps the start and end times to the current time by repeating the queue forward until the current day. For example, a 24-hour queue always begins at midnight of the current day.</para>
</listitem></deflistentry>
<deflistentry>
<term>END <replaceable>number</replaceable></term>
<listitem><para>The number of quanta from 0 that the segment ends at.</para>
</listitem></deflistentry>
<deflistentry>
<term>NCPUS <replaceable>number</replaceable></term>
<listitem><para>The number of CPUs.</para>
</listitem></deflistentry>
<deflistentry>
<term>MEMORY <replaceable>amount</replaceable></term>
<listitem><para>The amount of memory, specified by an integer followed by an optional unit of k for kilobytes, m for megabytes, or g for gigabytes. If no unit is specified, the default is bytes.</para>
</listitem></deflistentry>
</deflist>
<para>The following user queue definition file defines a queue using the policy named &ldquo;default&rdquo;. It has a quantum of 20 seconds and 3 elements to the vector definition. The start and end times of each multiple are specified in quanta, not in seconds.</para>
<itemizedlist>
<listitem><para>The first segment defines a resource multiple beginning at 00:00 and ending at 00:50, with 50 CPUs and 100&nbsp;MB of memory.</para>
</listitem>
<listitem><para>The second segment defines a resource multiple beginning at 00:51.67 and ending at 01:00, with 50 CPUs and 100&nbsp;MB.</para>
</listitem>
<listitem><para>The third segment defines a resource multiple beginning at 01:02.00 and ending at 01:03.33, also with 50 CPUs and 100&nbsp;MB of memory.</para>
<programlisting>POLICY default
QUANTUM 20
NSEG 3
&nbsp;
SEGMENT
START 0
END 150 (50min*60sec) / 20
NCPUS 50
MEMORY 100m
&nbsp;
SEGMENT
START 155 ((51min*60sec)+67) / 20
END 185 (1h*60min*60sec) / 20
NCPUS 50
MEMORY 100m
&nbsp;
SEGMENT
START 186 ((1h*60min*60sec)+(2min*60sec)) / 20
END 190 ((1h*60min*60sec)+(3min*60sec)+33sec) / 20
NCPUS 50
MEMORY 100m</programlisting>
</listitem></itemizedlist>
</section>
<section>
<title>Setting Up the Miser Configuration FIle</title>
<para><indexterm id="ITch07-13"><primary>Miser</primary><secondary>configuration file setup</secondary></indexterm>The Miser configuration file (<filename>/etc/miser.conf</filename>) lists the names of all Miser queues and the path name of the queue definition file for each queue. This file enumerates all the queue names and their queue definition files.</para>
<para>Every Miser configuration file must include as one of the queues the Miser system queue that defines the resources of the system pool. The Miser system queue is identified by the queue name &ldquo;system.&rdquo;</para>
<para>Valid tokens are as follows:</para>
<deflist termlength="nextline">
<deflistentry>
<term>QUEUE <replaceable>queue_name queue_definition_file_path</replaceable></term>
<listitem><para>The <replaceable>queue_name</replaceable> identifies the queue when using any interface to Miser. The queue name must be between 1 and 8 characters long. The queue name &ldquo;system&rdquo; is used to designate the Miser system queue.</para>
</listitem></deflistentry>
</deflist>
<para>The following is a sample Miser configuration file:</para>
<programlisting># Miser config file
QUEUE system /hosts/foobar/usr/local/data/system.conf
QUEUE user /hosts/foobar/usr/local/data/usr.conf</programlisting>
</section>
<section>
<title>Setting Up the Miser Command-line Options File</title>
<para><indexterm id="ITch07-14"><primary>Miser</primary><secondary>command-line options file setup</secondary></indexterm>The Miser command-line options file (<filename>/etc/config/miser.options</filename>) defines the maximum CPUs and memory that can be managed by Miser.</para>
<para>The <command>-c</command> flag defines the maximum number of CPUs that Miser can use. This value is the maximum number of CPUs that any resource segment of the system queue can reserve.</para>
<para>The <command>-m</command> flag defines the maximum memory that Miser can use. This value is the maximum memory that any resource segment of the system queue can reserve. The memory reserved for Miser comes from physical memory. The amount of memory that Miser uses should be less than the total physical memory, leaving enough memory for kernel use. Also, the system should have at least the amount of swap space configured for Miser so that if Miser memory is in full use, the system will have anough swap space to move previous non Miser submitted processes out of the way.</para>
<para>The following example sets the <command>-c</command> and <command>-m</command> values in the command-line options file to <replaceable>1</replaceable> and <replaceable>5</replaceable> megabytes, respectively:</para>
<programlisting>-f/etc/miser.conf -v -d -c 1 -m 5m </programlisting>
<para>The <command>-v</command> flag specifies verbose mode, which results in additional output.</para>
<para>The <command>-d</command> flag specifies debug mode. When this mode is specified, the application does not relinquish control of the tty (that is, it does not become a daemon). This mode is useful in conjunction with the <command>-v</command> flag to figure out why Miser may not be starting up correctly.</para>
<note><para>The <command>-C</command> flag can be used to release any Miser reserved resources after the Miser daemon is killed and before it is restarted. For additional information, see the <command sectionref="1">miser</command> reference page.</para>
</note>
</section>
<section>
<title>Configuration Recommendations</title>
<para><indexterm id="ITch07-15"><primary>Miser</primary><secondary>configuration recommendations</secondary></indexterm>The configuration of Miser is site dependent. The following guidelines may be helpful:</para>
<itemizedlist>
<listitem><para>The system must be balanced for interactive/batch use. One suggestion is to keep at least one or two processors outside the control of Miser at all times. These two processors will act as the interactive portion of the system when all of the Miser managed CPUs are reserved. For an interactive load, you typically want the load average for the CPUs to be less than 2.0. Keep this in mind as you adjust for the optimal number of free CPUs.</para>
</listitem>
<listitem><para>The amount of free logical swap should be balanced against the number of free CPUs. When you have a system with <replaceable>N</replaceable> CPUs, you should also have an appropriate amount of memory to be used by processes running on those <replaceable>N</replaceable> CPUs. Also, many system administrators like to back up this memory with swap space. If you think of the free CPUs as a separate system and provide memory and swap space accordingly, interactive work should perform well. Remember that the free memory not reserved by Miser is logical swap space (the combination of physical memory and the swap devices).</para>
</listitem>
<listitem><para>Be careful when using virtual swap. When no Miser application is running, time-share processes can consume all of physical memory. When Miser runs, it begins to reclaim physical memory and swaps out time-share processes. If the system is using virtual swap, there may be no physical swap to move the process to, and at that point the time-share process may be terminated.</para>
</listitem></itemizedlist>
</section>
</section>
<section>
<title>Miser Configuration Examples</title>
<para><indexterm id="ITch07-16"><primary>Miser</primary><secondary>configuration examples</secondary></indexterm>In the examples used in this section, the system has 12 CPUs and 160&nbsp;MB available to user programs.</para>
<para>Example 1:</para>
<para>In this example, the system is dedicated to batch scheduling with one queue, 24 hours a day.</para>
<para>The first step is to define a system queue. You must decide how long you want the system queue to be. The length of the system queue defines the maximum duration of any job submitted to the system. For this system, you have determined that the maximum duration for any one job can be 48 hours, so you define the system vector to have a duration of 48 hours.</para>
<programlisting># The system queue /usr/local/miser/system.conf
POLICY none # System queue has no policy
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 1
&nbsp;
SEGMENT
NCPUS 12
MEMORY 160m
START 0
END 8640 # Number of quanta (48h*60 min*60 sec) / 20</programlisting>
<para>The next step is to define a user queue.</para>
<programlisting># The user queue /usr/local/miser/physics.conf
POLICY default # First fit, once scheduled maintains start/end time
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 1
&nbsp;
SEGMENT
NCPUS 12
MEMORY 160m
START 0
END 8640 # Number of quanta (48h*60 min*60 sec) / 20</programlisting>
<para>The last step is to define a Miser configuration file:</para>
<programlisting># Miser config file
QUEUE system /usr/local/miser/system.conf
QUEUE physics /usr/local/miser/physics.conf</programlisting>
<para>Example 2:</para>
<para>In the following example, the system is dedicated to batch scheduling, 24 hours a day, and split between two user groups: chemistry and physics. The system must be divided between them with a ratio of 75% for physics and 25% for chermistry.</para>
<para>The system queue is identical to the one given in Example 1.</para>
<para>The physics user queue appears as follows:</para>
<programlisting># The physics queue /usr/local/miser/physics
POLICY default # System queue has no policy
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 1
&nbsp;
SEGMENT
NCPUS 8
MEMORY 120m
START 0
END 8640 # Number of quanta (48h*60min*60sec) / 20</programlisting>
<para>Next, you define the chemistry queue:</para>
<programlisting># The chemistry queue /usr/local/miser/chemistry.conf
POLICY default # System queue has no policy
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 1
&nbsp;
SEGMENT
NCPUS 4
MEMORY 40m
START 0
END 8640 # Number of quanta (48h*60min*60sec) / 20</programlisting>
<para>To restrict access to each queue, you create the user group physics and the user group chemistry. You then set the permissions on the physics queue definition file to execute only for group physics and similarly for the chemistry queue.</para>
<para>Having defined the physics and chemistry queue, you can now define the Miser configuration file:</para>
<programlisting># Miser configuration file
QUEUE system /usr/local/miser/system.conf
QUEUE physics /usr/local/miser/physics.conf
QUEUE chem /usr/local/miser/chemistry.conf</programlisting>
<para>Example 3:</para>
<para>In this example, the system is dedicated to time-sharing in the morning and to batch use in the evening. The evening is 8:00 P.M. to 4:00 A.M., and the morning is 4:00 A.M. to 8:00 P.M.</para>
<para>First you define the system queue.</para>
<programlisting># The system queue /hosts/foobar/usr/local/data/system.conf
POLICY none # System queue has no policy
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 2
&nbsp;
SEGMENT
NCPUS 12
MEMORY 160m
START 0
END 720 # (4h*60min*60sec) / 20
&nbsp;
SEGMENT
NCPUS 12
MEMORY 160m
START 3600 # (8pm is 20 hours from UTC, so 20h*60min*60sec) / 20
END 4320</programlisting>
<para>Next, you define the batch queue:</para>
<programlisting># User queue
POLICY repack # Repacks jobs (FIFO) if a job finishes early
QUANTUM 20 # Default quantum set to 20 seconds
NSEG 2
&nbsp;
SEGMENT
NCPUS 12
MEMORY 160m
START 0
END 720 # (4h*60min*60sec) / 20
&nbsp;
SEGMENT
NCPUS 12
MEMORY 160m
START 3600 # (8pm is 20 hours from 0, so 20h*60min*60sec) / 20
END 4320</programlisting>
<para>The last step is to define a Miser configuration file:</para>
<programlisting># Miser config file
QUEUE system /usr/local/miser/system.conf
QUEUE user /usr/local/miser/usr.conf</programlisting>
</section>
<section>
<title>Starting and Stopping Miser</title>
<para><indexterm id="ITch07-17"><primary>Miser</primary><secondary>starting</secondary></indexterm>After the Miser configuration files are modified appropriately, Miser can be selected for boot-time startup with the <command sectionref="1">chkconfig</command> command and the system can be rebooted, or Miser can be started directly by <emphasis>root</emphasis> with the command <literal>/etc/init.d/miser start</literal>. When starting Miser manually without rebooting, the <literal>chkconfig</literal> command must be issued first or Miser will not start up.</para>
<para>To start Miser manually, use the following command sequence:</para>
<literallayout><userinput>chkconfig miser on</userinput>
<userinput>/etc/init.d/miser start</userinput></literallayout>
<para><indexterm id="ITch07-18"><primary>Miser</primary><secondary>stopping</secondary></indexterm> Miser can be stopped at any time by <emphasis>root</emphasis> with the following command sequence:</para>
<literallayout><userinput>/etc/init.d/miser stop</userinput>
<?Pub Caret><userinput>/etc/init.d/miser cleanup</userinput></literallayout>
<para>Running Miser jobs are not stopped, and the current committed resources cannot be reclaimed until the jobs are terminated. If you are going to restart Miser after stopping it, you do not need to run the <literal>miser cleanup</literal> command.</para>
<note><para>The Miser <command>-C</command> flag can be used to release any Miser reserved resources after the Miser daemon is killed and before it is restarted.</para>
</note>
</section>
<section>
<title>Submitting Miser Jobs</title>
<para><indexterm id="ITch07-19"><primary>Miser</primary><secondary>submitting jobs</secondary></indexterm>The command to submit a job so that it is managed by Miser is as follows:</para>
<literallayout>miser_submit -q <replaceable>queue</replaceable> -o c=<replaceable>cpus</replaceable>,m=<replaceable>memory</replaceable>, t=<replaceable>time</replaceable>[,static] <replaceable>command</replaceable>
miser_submit -q <replaceable>queue</replaceable> -f <replaceable>file</replaceable>&ensp;<replaceable>command</replaceable></literallayout>
<deflist>
<deflistentry>
<term>-q <replaceable>queue</replaceable></term>
<listitem><para>Specifies the name of the queue against which to schedule the application.</para>
</listitem></deflistentry>
<deflistentry>
<term>-o c=<replaceable>cpus</replaceable>,m=<replaceable>memory</replaceable>, t=<replaceable>time</replaceable>[,static]</term>
<listitem><para>Specifies a block of resources. The CPUs must be an integer up to the maximum number of CPUs available to the queue being scheduled against. The memory consists of an integer followed by a unit of <emphasis>k</emphasis> for kilobyte, <emphasis>m</emphasis> for megabyte, or <emphasis>g</emphasis> for gigabyte. If no unit is specified, the default is bytes.Time can be specified either as an integer followed by a unit specifier of <emphasis>h</emphasis> for hours, <emphasis>m</emphasis> for minutes, or <emphasis>s</emphasis> for seconds, or by a string in the format <replaceable>hh</replaceable>:<replaceable>mm</replaceable><replaceable>:</replaceable><replaceable>ss</replaceable>.</para>
<para>A job with the <literal>static</literal> flag specified that was scheduled with the default policy will only run when the segment is scheduled to run. It will not run earlier even if idle resources are available to the job. If a job is scheduled with the repack policy, it may run earlier.</para>
</listitem></deflistentry>
<deflistentry>
<term>-f <replaceable>file</replaceable></term>
<listitem><para>File that specifies a list of resource segments. This flag allows greater control over the scheduling parameters of a job.</para>
</listitem></deflistentry>
<deflistentry>
<term><replaceable>command</replaceable></term>
<listitem><para>Specifies a script or program name.</para>
</listitem></deflistentry>
</deflist>
<para>For additional information, see the <command sectionref="1">miser_submit</command> and <command sectionref="4">miser_submit</command> reference pages.</para>
<section>
<title>Querying Miser About Job Schedule/Description</title>
<para><indexterm id="ITch07-20"><primary>Miser</primary><secondary>checking job status</secondary></indexterm>The command to query Miser about the schedule/description of a submitted job is as follows:</para>
<literallayout>miser_jinfo -j <replaceable>bid </replaceable>[-d]</literallayout>
<para>The <replaceable>bid</replaceable> is the ID of the Miser job and is the process group ID of the job. The -d flag prints the job description including job owner and command.</para>
<para>Note that when the system is being used heavily, Miser swapping can take some time. Therefore, the Miser job may not begin processing mmediately after it is submitted.</para>
<para>For additional information, see the <command sectionref="1">miser_jinfo</command> reference page.</para>
</section>
<section>
<title>Querying Miser About Queues</title>
<para><indexterm id="ITch07-21"><primary>Miser</primary><secondary>checking queue status</secondary></indexterm>The command to query Miser for information on Miser queues, queue resource status, and a list of jobs scheduled against a queue is as follows:</para>
<literallayout>miser_qinfo -Q|-q <replaceable>queue </replaceable>[-j]|-a</literallayout>
<para>The -Q flag returns a list of currently configured Miser queue names. The -q flag returns the free resources associated with the specified queue name. The -j flag returns the list of jobs currently scheduled against the queue. The -a flag returns a list of all scheduled jobs, ordered by job ID, in all configured Miser queues and also produces a brief description of the job.</para>
<para>For additional information, see the <command sectionref="1">miser_qinfo</command> reference page.</para>
</section>
<section>
<title>Moving a Block of Resources</title>
<para><indexterm id="ITch07-22"><primary>Miser</primary><secondary>checking queue status</secondary></indexterm>The command to move a block of resources from one queue to another is as follows:</para>
<literallayout>miser_move -s <replaceable>srcq </replaceable>-d <replaceable>destq</replaceable> -f <replaceable>file</replaceable>&ensp;
miser_move -s <replaceable>srcq </replaceable>-d <replaceable>destq</replaceable> -o s=<replaceable>start</replaceable>,e=<replaceable>end</replaceable>,c=<replaceable>CPUs</replaceable>,m=<replaceable>memory</replaceable></literallayout>
<para>This command removes a tuple of space from the source queue's vector and adds it to the destination queue's vector, beginning at the start time and ending at the end time. The resources added or removed do not change the vector definition, and are, therefore, temporary. The command returns a table that lists the start and end times of each resource transfer and the amount of resources transferred.</para>
<para>The -s and -d flags specify the names of any valid Miser queues. The -f flag contains a resource block specification. The -o flag specifies a block of resources to be moved. The start and end times are relative to the current time. The CPUs are an integer up to the maximum free CPUs associated with a queue. The memory is an integer with an identifier of <emphasis>k</emphasis> for kilobyte, <emphasis>m</emphasis> for megabyte, or <emphasis>g</emphasis> for gigabyte.</para>
<note><para>The resource transfer is temporary. If Miser is killed or crashes, the resources transferred are lost, and Miser will be unable to restart.</para>
</note>
<para>For additional information, see the <command sectionref="1">miser_move</command> and <command sectionref="4">miser_move</command> reference pages.</para>
</section>
<section>
<title>Resetting Miser</title>
<para><indexterm id="ITch07-23"><primary>Miser</primary><secondary>terminating a job</secondary></indexterm>The command to reset Miser with a new configuration file is as follows:</para>
<literallayout>miser_reset -f <replaceable>file</replaceable></literallayout>
<para>This command forces a running version of Miser to use a new configuration file (specified by -f <replaceable>file</replaceable>). The new configuration will succeed only if all scheduled jobs can be successfully scheduled against the new configuration.</para>
<para>For additional information, see the <command sectionref="1">miser_reset</command> reference page</para>
</section>
<section>
<title>Terminating a Miser Job</title>
<para><indexterm id="ITch07-24"><primary>Miser</primary><secondary>terminating a job</secondary></indexterm>The <literal>miser_kill</literal> command is used to terminate a job submitted to Miser. This command both terminates the process and contacts the Miser daemon to free any resources currently committed to the submitted process. For additional information, see the <command sectionref="1">miser_kill</command> reference page.</para>
</section>
</section>
<section>
<title>Miser and Batch Management Systems</title>
<para><indexterm id="ITch07-25"><primary>Miser</primary><secondary>differences between Miser and batch management systems</secondary></indexterm>This section discusses the differences between a Miser job and a batch job from a batch management system such as the <indexterm id="ITch07-26"><primary>Network Queuing Environment</primary></indexterm> Network Queuing Environment (<indexterm id="ITch07-27"><primary>WQE</primary></indexterm> NQE) or Load Share Facility (LSF).</para>
<para>Miser and batch management systems such as NQE each lack certain key characteristics. For Miser, these characteristics are features to protect and manage the Miser session. For batch management systems, the ability to guarantee resources is lacking. However, these two systems used together provide a much more capable solution, provided the batch management system supports the Miser scheduler.</para>
<para>If your site does not need the job management and protection provided by a batch management system, then Miser alone may be an adequate batch system. However, most production-quality environments require the support and protection provided by batch systems such as NQE or LSF. These sites should run a batch management system in cooperation with the Miser scheduler.</para>
</section>
</section>
<section>
<title>Defining and Managing cpusets</title>
<para><indexterm id="ITch07-28"><primary>Miser</primary><secondary>command-line options file setup</secondary></indexterm>The <literal>miser_cpuset</literal> command is used to define and manage a set of CPUs called a <indexterm id="ITch07-29"><primary>Miser</primary><secondary>logical swap space</secondary></indexterm><emphasis>cpuset</emphasis>. A cpuset is a named set of CPUs, which may be defined as restricted or open. The <literal>miser_cpuset</literal> command creates and destroys cpusets, retrieves information about existing cpusets, and attaches a process and all of its children to a cpuset.</para>
<note><para>The <literal>miser_cpuset</literal> command does not require the use of the Miser batch processing system. The <literal>miser_submit</literal> command cannot currently be used to submit jobs to cpuset queues.</para>
</note>
<para>A restricted cpuset only allows processes that are members of the cpuset to run on the set of CPUs. An open cpuset allows any process to run on its CPUs, but a process that is a member of the cpuset can only run on the CPUs belonging to the cpuset.</para>
<para>A cpuset is defined by a cpuset configuration file and a name. See the <command sectionref="4">miser_cpuset</command> reference page for a definition of the file format. The cpuset configuration file is used to list the CPUs that are members of the cpuset. It also contains any additional arguments required to define the cpuset. A cpuset name is between three and eight characters long; names of two or less characters are reserved.</para>
<para>The file permissions of the configuration file define access to the cpuset. When permissions need to be checked, the current permissions of the file are used. It is therefore possible to change access to a particular cpuset without having to tear it down and recreate it, simply by changing the acccess permission. Read access allows a user to retrieve information about a cpuset, while execute permission allows a user to attach a process to the cpuset.</para>
<para>The following is a sample configuration file that describes an exclusive cpuset containing 3 CPUs:</para>
<programlisting># cpuset configuration file
EXCLUSIVE
&nbsp;
CPU 1
CPU 5
CPU 10</programlisting>
<para>This specification will create a cpuset containing 3 CPUs and will restrict those CPUs to running threads that have been explicitly assigned to the cpuset.</para>
<note><para>Conflicts may occur between a CPU that a Miser queue is using and a CPU assigned to a cpuset. Miser does not have access to exclusively configured CPUs.</para>
</note>
<para>For a description of <literal>miser_cpuset</literal> command arguments and additional information, see the <command sectionref="1">miser_cpuset</command> and <command sectionref="4">miser_cpuset</command> reference pages.</para>
</section>
<section>
<title>Checkpoint and Restart</title>
<para>IRIX <indexterm id="ITch07-30"><primary>Checkpoint and Restart</primary></indexterm>Checkpoint and Restart (<indexterm id="ITch07-31"><primary>CPR</primary></indexterm>CPR) is a facility for saving the state of running processes, and for later resuming execution where the Checkpoint occurred. See the <link book="CPR_OG" extref="51170"><citetitle>IRIX Checkpoint and Restart Operation Guide</citetitle></link> and the <command sectionref="1">cpr</command> reference page for how to use and administer CPR.</para>
</section>
<section>
<title>NQE</title>
<para>The <indexterm id="ITch07-32"><primary>Network Queuing Environment</primary></indexterm>Network Queuing Environment (<indexterm id="ITch07-33"><primary>WQE</primary></indexterm>NQE) is a workload management environment that provides batch scheduling and interactive load balancing. See <citetitle>NQE Adminstration</citetitle> for how to configure, monitor and control NQE. Also see the following URL address:</para>
<para><olink appname="/usr/sbin/nr" parm1="http://www.cray.com/products/software/nqe">http://www.cray.com/products/software/nqe</olink></para>
</section>
<section>
<title>Share II</title>
<para><indexterm id="ITch07-34"><primary>ShareII</primary></indexterm>Share II is a resource-centric Fair Share scheduler that provides direct administrative control of system resource allocation. See the <link book="ShareII_AG" extref="23305"><citetitle>Share II for IRIX Administrator's Guide</citetitle></link> for how to configure and maintain Share II. Also see the following URL address:</para>
<para><olink appname="/usr/sbin/nr" parm1="http://www.softway.com.au/share2.html">http://www.softway.com.au/share2.html</olink></para>
</section>
<section>
<title>Performance Co-Pilot</title>
<para><indexterm id="ITch07-35"><primary>Performance Co-Pilot</primary></indexterm>Performance Co-Pilot (<indexterm id="ITch07-36"><primary>PCP</primary></indexterm>PCP) is a software package of advanced performance management applications. It provides a systems-level suite of tools that cooperate to deliver distributed, integrated performance monitoring and performance management services. See the <link book="PCP_UAG" extref="91944"><citetitle>Performance Co-Pilot User's and Administrator's Guide</citetitle></link> for how to administer PCP.</para>
</section>
</chapter>
<?Pub *0000064539 66035>
