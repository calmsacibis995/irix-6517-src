<!-- Produced by version 4.3 (11/99) of SGI Frame/SGIDOCBK SGML translator -->
<CHAPTER ID="LE30449-PARENT"><TITLE ID="LE30449-TITLE">System Performance Tuning</TITLE><PARA>This chapter describes the process by which you can improve your system performance. It covers the basics of t<INDEXTERM ID="ITch10-0"><PRIMARY>performance tuning</PRIMARY>
</INDEXTERM>
<INDEXTERM ID="ITch10-1"><PRIMARY>operating system, tuning</PRIMARY>
</INDEXTERM>
<INDEXTERM ID="ITch10-2"><PRIMARY>parameters, kernel</PRIMARY>
</INDEXTERM>
<INDEXTERM ID="ITch10-3"><PRIMARY>tuning the kernel</PRIMARY>
</INDEXTERM>
<INDEXTERM ID="ITch10-4"><PRIMARY>kernel tuning</PRIMARY>
</INDEXTERM>
uning the IRIX operating system for the best possible performance for your particular needs.</PARA>
<PARA>Your system is configured to run as fast as possible under most circumstances. However, you may find that adjusting certain parameters and operating system values may improve your total performance, or you may wish to optimize your system for some feature, such as disk access, to better make use of the graphics features or your application software.</PARA>
<PARA>Information provided includes the following topics:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>General information on system tuning and kernel parameters, including recommendations on parameter settings for large (64 processors) or greater systems. See <XREF LINKEND="LE83655-TITLE">..</PARA></LISTITEM>
<LISTITEM><PARA>Observing the operating system to determine if it should be tuned. See <XREF LINKEND="LE11632-TITLE">..</PARA></LISTITEM>
<LISTITEM><PARA>Tuning and reconfiguring the operating system. See <XREF LINKEND="LE10876-TITLE">..</PARA></LISTITEM>
<LISTITEM><PARA>Overcoming an unsuccessful reconfiguration attempt. See <XREF LINKEND="LE34306-PARENT"></PARA></LISTITEM>
<LISTITEM><PARA>Using multiple page sizes. See <XREF LINKEND="LE70628-PARENT"></PARA></LISTITEM>
</ITEMIZEDLIST>
<PARA>See <XREF LINKEND="LE80089-TITLE">, for information on <INDEXTERM ID="ITch10-5"><PRIMARY>tuning applications</PRIMARY></INDEXTERM>
<INDEXTERM ID="ITch10-6"><PRIMARY>applications, tuning</PRIMARY>
</INDEXTERM>
tuning applications under development.</PARA>
<SECTION  ID="LE83655-PARENT"><TITLE  ID="LE83655-TITLE">About System Performance Tuning</TITLE><PARA>The standard IRIX system configuration is designed for a broad range of uses, and adjusts itself to operate efficiently under all but the most unusual and extreme conditions. The operating system controls the execution of programs in memory and the movement of programs from disk to memory and back to disk.</PARA>
<PARA>The basic method of system tuning is as follows:</PARA>
<ORDEREDLIST><LISTITEM><PARA>Monitor system performance using various utilities.</PARA>
</LISTITEM>
<LISTITEM><PARA>Adjust specific values (for example, the maximum number of processes).</PARA>
</LISTITEM>
<LISTITEM><PARA>Reboot the system if necessary.</PARA>
</LISTITEM>
<LISTITEM><PARA>Test the performance of the new system to see if it is improved.</PARA>
</LISTITEM>
</ORDEREDLIST>
<PARA>Note that performance tuning cannot expand the capabilities of a system beyond its hardware capacity. You may need to add hardware, in particular another disk or additional memory, to improve performance.</PARA>
<SECTION  ID="LE71826-PARENT"><TITLE  ID="LE71826-TITLE">Files Used for Kernel Tuning</TITLE><PARA><XREF LINKEND="LE32779-TITLE"> lists the files/directories used for tuning and reconfiguring a system.</PARA><TABLE FRAME="topbot"><TBLTITLE  ID="LE32779-TITLE">Files and Directories Used for Tuning</TBLTITLE>
<TGROUP COLS="2">
<COLSPEC COLWIDTH="252*">
<COLSPEC COLWIDTH="532*">
<THEAD><ROW><ENTRY><PARA>File/Directory</PARA></ENTRY>
<ENTRY><PARA>Purpose</PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA><FILENAME>/var/sysgen/system/</FILENAME>*</PARA></ENTRY>
<ENTRY><PARA>Directory containing files defining software modules</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><FILENAME>/var/sysgen/master.d</FILENAME></PARA></ENTRY>
<ENTRY><PARA>Directory containing files defining kernel switches and 
parameters</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><FILENAME>/var/sysgen/mtune/*</FILENAME></PARA></ENTRY>
<ENTRY><PARA>Directory containing files defining more tunable parameters</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><FILENAME>/var/sysgen/stune</FILENAME></PARA></ENTRY>
<ENTRY><PARA>File defining default parameter values</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><FILENAME>/var/sysgen/boot/*</FILENAME></PARA></ENTRY>
<ENTRY><PARA>Directory of object files</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><FILENAME>/unix</FILENAME></PARA></ENTRY>
<ENTRY><PARA>File containing kernel image</PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
<PARA>Typically you tune a parameter in one of the files located in the <FILENAME>mtune</FILENAME> directory (for example, the <FILENAME>kernel</FILENAME> file) by using the<COMMAND>&ensp;systune</COMMAND> command. For information about <COMMAND>systune</COMMAND>, see the <COMMAND>systune(1M)</COMMAND> man page.</PARA>
</SECTION>
<SECTION><TITLE>Overview of Kernel Tunable Parameters</TITLE><PARA>Tunable parameters control characteristics of processes, files, and system activity. They set various table sizes and system thresholds to handle the expected system load. If certain system structures are too large, they waste memory space that would be used for other processes and can increase system overhead due to lengthy table searches. If they are set too low, they can cause excessive I/O, process aborts, or even a system crash, depending on the particular parameter.</PARA>
<PARA>This section briefly introduces some of the tunable parameters and switches. <XREF LINKEND="LE55153-TITLE">, describes all parameters, gives default values, provides suggestions on when to change each parameter, and describes problems you may encounter.</PARA><PARA>Tunable parameters are specified in separate configuration files in the <FILENAME>/var/sysgen/mtune</FILENAME> and the <FILENAME>/var/sysgen/master.d</FILENAME> directories. For <FILENAME>mtune</FILENAME> and <FILENAME>master.d</FILENAME> information, see the <COMMAND>mtune(4)</COMMAND>and <COMMAND>master(4)</COMMAND> man pages.</PARA>
<PARA>The default values for the tunable parameters are usually acceptable for most configurations for a single-user workstation environment. If you have a lot of memory or your environment has special needs, you may want to adjust the size of a parameter to meet those needs. A few of the parameters you may want to adjust are listed below.</PARA>
<DEFLIST><DEFLISTENTRY><TERM><LITERAL>nproc</LITERAL> </TERM>
<LISTITEM><PARA>Maximum number of processes, systemwide, typically auto-configured</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>maxup</LITERAL> </TERM>
<LISTITEM><PARA>Maximum number of processes per UID</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>rlimit_core_cur</LITERAL></TERM>
<LISTITEM><PARA>Maximum size of a core file</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>rlimit_data_cur</LITERAL></TERM>
<LISTITEM><PARA>Maximum amount of data space available to a process</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>rlimit_fsize_cur</LITERAL></TERM>
<LISTITEM><PARA>Maximum file size available to a process</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>rlimit_nofile_cur</LITERAL></TERM>
<LISTITEM><PARA>Maximum number of file descriptors available to a process</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>rlimit_rss_cur</LITERAL></TERM>
<LISTITEM><PARA>Maximum resident set size available to a process</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>rlimit_vmem_cur</LITERAL></TERM>
<LISTITEM><PARA>Maximum amount of mapped memory for a process</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>sshmseg</LITERAL></TERM>
<LISTITEM><PARA>Maximum number of attached shared memory segments per process </PARA>
</LISTITEM>
</DEFLISTENTRY>
</DEFLIST>
</SECTION>
<SECTION><TITLE>Large System Tunable Parameters</TITLE><PARA><INDEXTERM ID="ITch10-7"><PRIMARY>parameters, large system tuning</PRIMARY>
</INDEXTERM>
<XREF LINKEND="LE61781-TITLE"> lists the system tuning parameters recommended for large (64 processors or greater) systems. See <XREF LINKEND="LE55153-TITLE">, for detailed descriptions of each of these parameters.</PARA><NOTE><PARA>These parameters are highly system-dependent. The values listed are recommended initial values. You may want to alter them for a specific system or set of applications, and then evaluate the results of the changes.</PARA>
</NOTE>
<PARA>Note also that the kernel forces the value of the <LITERAL>maxup</LITERAL> parameter to be less than the value of the <KEYCAP>nproc</KEYCAP> parameter by 20. While setting the value of <LITERAL>maxup</LITERAL> to be equal to or greater than <KEYCAP>nproc</KEYCAP> will work in <COMMAND>systune</COMMAND>, the next time the system is rebooted or the kernel is reconfigured, the limit to <LITERAL>maxup</LITERAL> of <KEYCAP>nproc</KEYCAP> minus 20 will be enforced. See the <COMMAND>systune(1M)</COMMAND> man page for more information on <COMMAND>systune</COMMAND>.</PARA>
<TABLE FRAME="topbot"><TBLTITLE  ID="LE61781-TITLE">Large System Tunable Parameters</TBLTITLE>
<TGROUP COLS="2">
<COLSPEC COLWIDTH="366*">
<COLSPEC COLWIDTH="264*">
<THEAD><ROW><ENTRY><PARA>Parameter</PARA></ENTRY>
<ENTRY><PARA>Recommended Initial Value</PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA><LITERAL>dump_level</LITERAL></PARA></ENTRY>
<ENTRY><PARA>3</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>maxdmasz</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0x2001</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rsshogfrac</LITERAL></PARA></ENTRY>
<ENTRY><PARA>99</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_stack_max</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0x20000000 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_stack_cu<REPLACEABLE></REPLACEABLE><REPLACEABLE>r</REPLACEABLE></LITERAL></PARA></ENTRY>
<ENTRY><PARA>0x04000000 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_rss_max</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0x20000000 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_rss_cur</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_data_max</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_data_cur</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rlimit_vmem_max</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><KEYCAP>rlimit_vmem_cur</KEYCAP></PARA></ENTRY>
<ENTRY><PARA>0 ll</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>nbuf</LITERAL></PARA></ENTRY>
<ENTRY><PARA>2000</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>syssegsz</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0xfe800</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>sshmseg</LITERAL></PARA></ENTRY>
<ENTRY><PARA>250</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>shmmax</LITERAL></PARA></ENTRY>
<ENTRY><PARA>(0x4000000) 11</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>semmni</LITERAL></PARA></ENTRY>
<ENTRY><PARA>2000</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>semume</LITERAL></PARA></ENTRY>
<ENTRY><PARA>80</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>semopm</LITERAL></PARA></ENTRY>
<ENTRY><PARA>80</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>semmns</LITERAL></PARA></ENTRY>
<ENTRY><PARA>2000</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>gpgshi</LITERAL></PARA></ENTRY>
<ENTRY><PARA>2000</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>gpgslo</LITERAL></PARA></ENTRY>
<ENTRY><PARA>1000</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>maxup</LITERAL></PARA></ENTRY>
<ENTRY><PARA>7980</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>nproc</LITERAL></PARA></ENTRY>
<ENTRY><PARA>8000</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>percent_totalmem_1m_pages</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>percent_totalmem_4m_pages</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>percent_totalmem_16m_pages</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>percent_totalmem_64k_pages</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>percent_totalmem_256k_pages</LITERAL></PARA></ENTRY>
<ENTRY><PARA>0</PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
</SECTION>
</SECTION>
<SECTION  ID="LE11632-PARENT"><TITLE  ID="LE11632-TITLE">Monitoring the Operating System </TITLE><PARA>Before you make any changes to your kernel parameters, learn which parameters should be changed and why. Monitoring the functions of the operating system will help you determine if changing parameters will help your performance, or if new hardware is necessary.</PARA>
<SECTION><TITLE>Receiving Kernel Messages and Adjusting Table Sizes </TITLE><PARA>In rare instances, a table overflows because it is not large enough to meet the needs of the system. In this case, an error message appears on the console and in <FILENAME>/var/adm/SYSLOG</FILENAME>. If the console window is closed or stored, check <FILENAME>SYSLOG</FILENAME> periodically.</PARA>
<PARA>Some system calls return an error message that can indicate a number of conditions, one of which is that you need to increase the size of a parameter. <XREF LINKEND="LE35574-TITLE"> lists the error messages and parameters that may need adjustment. These parameters are in <FILENAME>/var/sysgen/master.d/kernel</FILENAME>.</PARA>
<TABLE FRAME="topbot"><TBLTITLE  ID="LE35574-TITLE">System Call Errors and Related Parameters</TBLTITLE>
<TGROUP COLS="3">
<COLSPEC COLWIDTH="392*">
<COLSPEC COLWIDTH="154*">
<COLSPEC COLWIDTH="244*">
<THEAD><ROW><ENTRY><PARA>Message</PARA></ENTRY>
<ENTRY><PARA>System Call</PARA></ENTRY>
<ENTRY><PARA>Parameter </PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA><LITERAL>EAGAIN</LITERAL> <NEWLINE>
<LITERAL>No more processes</LITERAL></PARA></ENTRY>
<ENTRY><PARA><COMMAND>fork(2)</COMMAND></PARA></ENTRY>
<ENTRY><PARA>Increase <LITERAL>nproc</LITERAL> or swap 
space</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>ELIBMAX</LITERAL> <NEWLINE>
<LITERAL>linked more shared libraries than 
limit</LITERAL></PARA></ENTRY>
<ENTRY><PARA><COMMAND>exec(2)</COMMAND></PARA></ENTRY>
<ENTRY><PARA>Increase the <LITERAL>shlbmax 
</LITERAL>tunable parameter.</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>E2BIG</LITERAL> <NEWLINE>
<LITERAL>Arg list too long</LITERAL></PARA></ENTRY>
<ENTRY><PARA><COMMAND>shell(1)</COMMAND>, </PARA><PARA><COMMAND>make(1)</COMMAND>,</PARA><PARA><COMMAND>exec(2)</COMMAND></PARA></ENTRY>
<ENTRY><PARA>Increase the <LITERAL>ncargs</LITERAL> 
tunable parameter.</PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
<PARA>Be aware that there can be other reasons for these errors. For example, <LITERAL>EAGAIN</LITERAL> may appear because of insufficient virtual memory. In this case, you may need to add more swap space. For other conditions that can cause these messages, see the owner's guide appendix on error messages.</PARA>
<PARA>Other system calls fail and return error messages that may indicate IPC (interprocess communication) structures need adjustment. These messages and the parameters to adjust are listed in <XREF LINKEND="LE55153-TITLE">.</PARA></SECTION>
<SECTION  ID="LE86117-PARENT"><TITLE  ID="LE86117-TITLE">About timex, sar, and par</TITLE><PARA>Three utilities you can use to monitor system performance are <COMMAND>timex</COMMAND>, <COMMAND>sar</COMMAND>, and <COMMAND>par</COMMAND>. They provide very useful information about what is happening in the system.</PARA>
<PARA>The operating system has a number of counters that measure internal system activity. Each time an operation is performed, an associated counter is incremented. You can monitor internal system activity by reading the values of these counters.</PARA>
<PARA>The <COMMAND>timex</COMMAND> and <COMMAND>sar</COMMAND> utilities monitor the value of the operating system counters, and thus sample system performance. Both utilities use <COMMAND>sadc</COMMAND>, the <COMMAND>sar</COMMAND> data collector, which collects data from the operating system counters and puts it in a file in binary format. The difference is that <COMMAND>timex</COMMAND> takes a sample over a single span of time, while <COMMAND>sar</COMMAND> takes a sample at specified time intervals. The <COMMAND>sar</COMMAND> program also has options that allow sampling of a specific function such as CPU usage (<LITERAL>-u</LITERAL> option) or paging (<LITERAL>-p</LITERAL> option). In addition, the utilities display the data differently.</PARA>
<PARA>The <COMMAND>par</COMMAND> utility has the ability to trace system call and scheduling activity. It can be used to trace the activity of a single process, a related group of processes, or the system as a whole.</PARA>
<PARA>When would you use one utility over the other? If you are running a single application or a couple of programs, use <COMMAND>timex</COMMAND>. If you have a multiuser/multiprocessor system and/or are running many programs, use <COMMAND>sar</COMMAND> or <COMMAND>par</COMMAND>.</PARA>
<PARA>As in all performance tuning, be sure to run these utilities at the same time you are running an application or a benchmark, and be concerned only when figures are outside the acceptable limits over a period of time.</PARA>
<SECTION><TITLE>Using timex </TITLE><PARA>The <COMMAND>timex</COMMAND> utility is a useful troubleshooting tool when you are running a single application. For example:</PARA>
<PROGRAMLISTING>
<USERINPUT>timex -s </USERINPUT><REPLACEABLE>application</REPLACEABLE>
</PROGRAMLISTING>
<PARA>The <LITERAL>-s</LITERAL> option reports total system activity (not just that due to the application) that occurred during the execution interval of <REPLACEABLE>application</REPLACEABLE>. To redirect <COMMAND>timex</COMMAND> output to a file, (assuming you use the Bourne shell, (<COMMAND>sh(1)</COMMAND>) enter:</PARA>
<PROGRAMLISTING>
<USERINPUT>timex -s </USERINPUT><REPLACEABLE>application</REPLACEABLE><USERINPUT>&ensp;2&gt; file</USERINPUT>
</PROGRAMLISTING>
<PARA>The same command, entered using the C shell, looks like this:</PARA>
<PROGRAMLISTING>
<USERINPUT>timex -s </USERINPUT><REPLACEABLE>application</REPLACEABLE><USERINPUT>&ensp;&gt; file</USERINPUT>
</PROGRAMLISTING>
</SECTION>
<SECTION><TITLE>Using sar </TITLE><PARA>The <COMMAND>sar</COMMAND> utility is a useful troubleshooting tool when you are running many programs and processes and/or have a multiuser system such as a server. You can take a sample of the operating system counters over a period of time (for a day, a few days, or a week).</PARA>
<PARA>Depending on your needs, you can choose the way in which you examine system activity. You can monitor the system:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>During daily operation</PARA>
</LISTITEM>
<LISTITEM><PARA>Consecutively with an interval</PARA>
</LISTITEM>
<LISTITEM><PARA>Before and after an activity under your control</PARA>
</LISTITEM>
<LISTITEM><PARA>During the execution of a command</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>You can set up the system so that <COMMAND>sar</COMMAND> automatically collects system activity data and puts it into files for you. Use the <COMMAND>chkconfig</COMMAND> command to turn on <COMMAND>sar</COMMAND>'s automatic reporting feature, which generates a <COMMAND>sar -A</COMMAND> listing. A <COMMAND>crontab</COMMAND> entry instructs the system to sample the system counters every 20 minutes during working hours and every hour at other times for the current day (data is kept for the last 7 days). To enable this feature, type:</PARA>
<PROGRAMLISTING>
<USERINPUT>/etc/chkconfig sar on</USERINPUT>
</PROGRAMLISTING>
<PARA>The collected data is put in <FILENAME>/var/adm/sa</FILENAME> in the form <REPLACEABLE>sann</REPLACEABLE> and <REPLACEABLE>sarnn</REPLACEABLE>, where <REPLACEABLE>nn</REPLACEABLE> is the date of the report (<REPLACEABLE>sarnn</REPLACEABLE> is in ASCII format). You can use the <COMMAND>sar(1M)</COMMAND> command to output the results of system activity.</PARA>
</SECTION>
<SECTION><TITLE>Using sar Consecutively with a Time Interval</TITLE><PARA>You can use <COMMAND>sar</COMMAND> to generate consecutive reports about the current state of the system. On the command line, specify a time interval and a count. For example:</PARA>
<PROGRAMLISTING>
<USERINPUT>sar -u 5 8</USERINPUT>
</PROGRAMLISTING>
<PARA>This prints information about CPU use eight times at five-second intervals.</PARA>
</SECTION>
<SECTION><TITLE>Using sar before and after a User-Controlled Activity</TITLE><PARA>You may find it useful to take a snapshot of the system activity counters before and after running an application (or after running several applications concurrently). To take a snapshot of system activity, instruct <COMMAND>sadc</COMMAND> (the data collector) to dump its output into a file. Then run the application(s) either under normal system load or restricted load, and when you are ready to stop recording, take another snapshot of system activity. Then compare results to see what happened.</PARA>
<PARA>Following is an example of commands that samples the system counters before and after the application:</PARA>
<PROGRAMLISTING>
<USERINPUT>/usr/lib/sa/sadc 1 1 file</USERINPUT>
</PROGRAMLISTING>
<PARA>Run the application(s) or perform any work you want to monitor, then type:</PARA>
<PROGRAMLISTING>
<USERINPUT>/usr/lib/sa/sadc 1 1 file</USERINPUT>
<USERINPUT>sar -f file</USERINPUT>
</PROGRAMLISTING>
<PARA>If <LITERAL>file</LITERAL> does not exist, <COMMAND>sadc</COMMAND> creates it. If it does exist, <COMMAND>sadc</COMMAND> appends data to it.</PARA>
</SECTION>
<SECTION><TITLE>Using sar and timex during the Execution of a Command</TITLE><PARA>Often you want to examine system activity during the execution of a command or set of commands. For example, to examine all system activity while running <COMMAND>nroff(1)</COMMAND>, type:</PARA>
<PROGRAMLISTING>
<USERINPUT>/usr/lib/sa/sadc 1 1 sa.out <NEWLINE>nroff -mm file.mm &gt; file.out <NEWLINE>/usr/lib/sa/sadc 1 1 sa.out <NEWLINE>sar -A -f sa.out </USERINPUT>
</PROGRAMLISTING>
<PARA>By using <COMMAND>timex</COMMAND>, you can do the same thing with one line of code:</PARA>
<PROGRAMLISTING>
<USERINPUT>timex -s nroff -mm file.mm &gt; file.out</USERINPUT>
</PROGRAMLISTING>
<PARA>Note that the <COMMAND>timex</COMMAND> also includes the real, user, and system time spent executing the <COMMAND>nroff</COMMAND> request.</PARA>
<PARA>There are two minor differences between <COMMAND>timex</COMMAND> and <COMMAND>sar</COMMAND>. The <COMMAND>sar</COMMAND> program can limit its output (such as, the <LITERAL>-u</LITERAL> option reports only CPU activity), while <COMMAND>timex</COMMAND> always prints the <LITERAL>-A</LITERAL> listing. Also, <COMMAND>sar</COMMAND> works in a variety of ways, but <COMMAND>timex</COMMAND> only works by executing a command&mdash;however, the command can be a shell file.</PARA>
<PARA>If you are interested in system activity during the execution of two or more commands running concurrently, put the commands into a shell file and run <COMMAND>timex -s</COMMAND> on the file. For example, suppose the file <FILENAME>nroff.sh</FILENAME> contained the following lines:</PARA>
<PROGRAMLISTING>
nroff -mm file1.mm &gt; file1.out &amp;
nroff -mm file2.mm &gt; file2.out &amp;
wait
</PROGRAMLISTING>
<PARA>To get a report of all system activity after both of the <COMMAND>nroff</COMMAND> requests (running concurrently) finish, invoke <COMMAND>timex</COMMAND> as follows:</PARA>
<PROGRAMLISTING>
<USERINPUT>timex -s nroff.sh</USERINPUT>
</PROGRAMLISTING>
</SECTION>
<SECTION><TITLE>Using par</TITLE><PARA>You can use <COMMAND>par</COMMAND> in much as you use <COMMAND>sar</COMMAND>:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>During daily operation</PARA>
</LISTITEM>
<LISTITEM><PARA>Consecutively with an interval</PARA>
</LISTITEM>
<LISTITEM><PARA>Before and after an activity under your control</PARA>
</LISTITEM>
<LISTITEM><PARA>During the execution of a command</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>See the <COMMAND>par(1)</COMMAND> man page for specifics on usage.</PARA>
<PARA>Use <COMMAND>par</COMMAND> instead of <COMMAND>sar</COMMAND> when you want a finer look at a suspect or problem process. Instead of simply telling you how much total time was used while your process was executing, like <COMMAND>timex</COMMAND>, <COMMAND>par</COMMAND> breaks down the information so you can get a better idea of what parts of the process are consuming time. In particular, use the following command options:</PARA>
<DEFLIST><DEFLISTENTRY><TERM><LITERAL>-isSSdu</LITERAL></TERM>
<LISTITEM><PARA>Checks the time used by each system call and the intervening time lag.</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><LITERAL>-rQQ</LITERAL></TERM>
<LISTITEM><PARA>Checks process scheduling, to see if it should be run more or less frequently.</PARA>
</LISTITEM>
</DEFLISTENTRY>
</DEFLIST>
<PARA>When tracing system calls, <COMMAND>par</COMMAND> prints a report showing all system calls made by the subject processes complete with arguments and return values. In this mode, <COMMAND>par</COMMAND> also reports all signals delivered to the subject processes. In schedule tracing mode, <COMMAND>par</COMMAND> prints a report showing all scheduling events taking place in the system during the measurement period. The report shows each time a process is put on the run queue, started on a processor, and unscheduled from a processor, including the reason that the process was unscheduled. The events include timestamps. You can set up the system so <COMMAND>par</COMMAND> automatically collects system activity data and puts it into files for you.</PARA>
<PARA>The <COMMAND>par</COMMAND> utility works by processing the output of <COMMAND>padc(1)</COMMAND>. This can be done in two ways: <COMMAND>padc</COMMAND> can be run separately and the output saved in a file to be fed to <COMMAND>par</COMMAND> as a separate operation, or <COMMAND>padc</COMMAND> can be invoked by <COMMAND>par</COMMAND> to perform the data collection and reporting in one step.</PARA>
<PARA>The <COMMAND>par</COMMAND> utility can provide different types of reports from a given set of <COMMAND>padc</COMMAND> data depending on the reporting options that are specified. This is a reason why it is sometimes desirable to run the data collection as a separate step.</PARA>
</SECTION>
<SECTION><TITLE>Summary of sar, par, and timex</TITLE><PARA>Now that you have learned when and how to use <COMMAND>par</COMMAND>, <COMMAND>sar</COMMAND>, and <COMMAND>timex</COMMAND>, you can choose one of these utilities to monitor the operating system. Then examine the output and try to determine what is causing performance degradation. Look for numbers that show large fluctuation or change over a sustained period; do not be too concerned if numbers occasionally go beyond the maximum.</PARA>
<PARA>The first thing to check is how the system is handling the disk I/O process. After that, check for excessive paging/swapping. Finally look at CPU use and memory allocation.</PARA>
<PARA>The following sections assume that the system you are tuning is active (with applications/benchmark executing).</PARA>
</SECTION>
</SECTION>
<SECTION><TITLE>Disk I/O Performance</TITLE><PARA>The system uses disks to store data, and transfers data between the disk and memory. This input/output (I/O) process consumes a lot of system resources; so you want the operating system to be as efficient as possible when it performs I/O.</PARA>
<SECTION><TITLE>Checking Disk I/O</TITLE><PARA>If you are going to run a large application or have a heavy system load, the system benefits from disk I/O tuning. Run <COMMAND>sar -A</COMMAND> or <COMMAND>timex -s</COMMAND> and look at the %busy, <LITERAL>%rcache</LITERAL>, <LITERAL>%wcache</LITERAL>, and <LITERAL>%wio</LITERAL> fields. To see if your disk subsystem needs tuning, check your output of <COMMAND>sar -A</COMMAND> against the figures in <XREF LINKEND="LE47651-TITLE">. (Note that in this table, the right column lists the <COMMAND>sar</COMMAND> option that prints only selected output, for example, output for disk usage (<COMMAND>sar -d</COMMAND>) or CPU activity (<COMMAND>sar -u</COMMAND>).)</PARA>
<PARA><XREF LINKEND="LE47651-TITLE"> lists <COMMAND>sar</COMMAND> results that indicate an I/O-bound system.</PARA>
<TABLE FRAME="topbot"><TBLTITLE  ID="LE47651-TITLE">Indications of an I/O-Bound System</TBLTITLE>
<TGROUP COLS="3">
<COLSPEC COLWIDTH="320*">
<COLSPEC COLWIDTH="234*">
<COLSPEC COLWIDTH="234*">
<THEAD><ROW><ENTRY><PARA>Field</PARA></ENTRY>
<ENTRY><PARA>Value</PARA></ENTRY>
<ENTRY><PARA>sar Option </PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA><LITERAL>%busy</LITERAL> (% time disk is busy)</PARA></ENTRY>
<ENTRY><PARA>&gt;85%</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -d</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>%rcache</LITERAL> (reads in buffer cache)</PARA></ENTRY>
<ENTRY><PARA>low, &lt;85</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -b</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>%wcache</LITERAL> (writes in buffer cache)</PARA></ENTRY>
<ENTRY><PARA>&ensp;low, &lt;60%</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -b</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>%wio</LITERAL> (idle CPU waiting for disk I/O)</PARA></ENTRY>
<ENTRY><PARA>dev. system &gt;30<NEWLINE>
fileserver &gt;80</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -u</COMMAND></PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
<PARA>Notice that for the <LITERAL>%wio</LITERAL> figures (indicates the percentage of time the CPU is idle while waiting for disk I/O), there are examples of two types of systems:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>A development system that has users who are running programs such as <COMMAND>make</COMMAND>. In this case, if <LITERAL>%wio &gt; 30</LITERAL>, check the breakdown of <LITERAL>%wio</LITERAL> (<COMMAND>sar -u</COMMAND>). By looking at the <LITERAL>%wfs</LITERAL> (waiting for filesystem) and <LITERAL>%wswp</LITERAL> (waiting for swap), you can pinpoint exactly what the system is waiting for.</PARA>
</LISTITEM>
<LISTITEM><PARA>An NFS system that is serving NFS clients and is running as a file server. In this case, if <LITERAL>%wio &gt; 80</LITERAL>, <LITERAL>%wfs &gt; 90</LITERAL>, the system is disk I/O bound.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>There are many other factors to consider when you tune for maximum I/O performance. You may also be able to increase performance by:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Using logical volumes</PARA>
</LISTITEM>
<LISTITEM><PARA>Using partitions on different disks</PARA>
</LISTITEM>
<LISTITEM><PARA>Adding hardware (a disk, controller, memory)</PARA>
</LISTITEM>
</ITEMIZEDLIST>
</SECTION>
<SECTION><TITLE>About Logical Volumes for Improving Disk I/O </TITLE><PARA>By using logical volumes, you can improve disk I/O:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>You can increase the size of an existing filesystem without having to disturb the existing filesystem contents.</PARA>
</LISTITEM>
<LISTITEM><PARA>You can stripe filesystems across multiple disks. You may be able to obtain up to 50% improvement in your I/O throughput by creating striped volumes on disks.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>Striping works best on disks that are on different controllers. Logical volumes give you more space without remaking the first filesystem. Disk striping gives you more space with increased performance potential, but you run the risk that if you lose one of the disks with striped data, you lose all the data on the filesystem, since the data is interspersed across all the disks.</PARA>
<PARA>Contiguous logical volumes fill up one disk, and then write to the next. Striped logical volumes write to both disks equally, spreading each file across all disks in the volume. It is impossible to recover from a bad disk if the data is striped, but it is possible if the data is in a contiguous logical volume. For information on creating a striped disk volume, see the <CITETITLE><LINK BOOK="IA_DiskFiles" EXTREF="88526">IRIX Admin: Disks and Filesystems</LINK>
</CITETITLE> guide.</PARA>
</SECTION>
<SECTION  ID="LE19901-PARENT"><TITLE  ID="LE19901-TITLE">About Partitions and Additional Disks for Improving Disk I/O</TITLE><PARA>There are obvious ways to increase your system's throughput, such as limiting the number of programs that can run at peak times, shifting processes to non-peak hours (run batch jobs at night), and shifting processes to another system. You can also set up partitions on separate disks to redistribute the disk load or add disks.</PARA>
<PARA>Before continuing with the discussion about partitions, look at how a program uses a disk as it executes. <XREF LINKEND="LE11613-TITLE"> shows various reasons why an application may need to access the disk.</PARA><TABLE FRAME="topbot"><TBLTITLE  ID="LE11613-TITLE">Disk Access of an Application</TBLTITLE>
<TGROUP COLS="2">
<COLSPEC COLWIDTH="294*">
<COLSPEC COLWIDTH="196*">
<THEAD><ROW><ENTRY><PARA>Application</PARA></ENTRY>
<ENTRY><PARA>Disk Access </PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA>Execute object code.</PARA></ENTRY>
<ENTRY><PARA>Text and data</PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA>Use swap space for data, stack.</PARA></ENTRY>
<ENTRY><PARA><FILENAME>/dev/swap</FILENAME></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA>Write temporary files.</PARA></ENTRY>
<ENTRY><PARA><FILENAME>/tmp</FILENAME> and <FILENAME>/var/tmp</FILENAME></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA>Reads/writes data files.</PARA></ENTRY>
<ENTRY><PARA>Data files</PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
<PARA>You can maximize I/O performance by using separate partitions on different disks for some of the disk access areas. In effect, you are spreading out the application's disk access routines, which speeds up I/O.</PARA>
<PARA>By default, disks are partitioned to allow access in one of two ways:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Two partitions: partitions 0 and 1</PARA>
</LISTITEM>
<LISTITEM><PARA>One large partition: partition 7 (encompasses the two smaller partitions)</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>On the system disk, partition 0 is for <LITERAL>root</LITERAL> and partition 1 is for <LITERAL>swap</LITERAL>.</PARA>
<NOTE><PARA>On older systems, disks may have three partitions: partitions 0, 1, and 6. On the system disk, partition 0 is for <LITERAL>root</LITERAL>, 1 is for <LITERAL>swap</LITERAL>, and 6 is for <FILENAME>/usr</FILENAME>. If there is one large partition, it encompasses the three smaller partitions.</PARA>
</NOTE>
<PARA>For each additional disk, decide if you want a number of partitions or one large one and the filesystems (or swap) you want on each disk and partition. It is best to distribute filesystems in the disk partitions so that different disks are being accessed concurrently.</PARA>
<PARA>The configuration depends on how you use the system; so it helps to look at a few examples.</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Consider a system that typically runs a single graphics application that often reads from a data file. The application is so large that its pages are often swapped out to the swap partition.</PARA>
<PARA>In this case, it might make sense to have the application's data file on a disk separate from the swap area.</PARA>
</LISTITEM>
<LISTITEM><PARA>If after configuring the system this way, you find that it does not have enough swap space, consider either obtaining more memory, or backing up everything on the second hard disk and creating partitions to contain both a swap area and a data area.</PARA>
</LISTITEM>
<LISTITEM><PARA>Changing the size of a partition containing an existing filesystem may make any data in that filesystem inaccessible. Always do a complete and current backup (with verification) and document partition information before making a change. If you change the wrong partition, you can change it back, providing you do not run <COMMAND>mkfs</COMMAND> on it or overwrite it. It is recommended that you print a copy of the <COMMAND>prtvtoc</COMMAND> command output after you have customized your disks, so that they may be more easily restored in the event of severe disk damage.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>If you have a very large application and have three disks, consider using partitions on the second and third disks for the application's executables (<FILENAME>/bin</FILENAME> and <FILENAME>/usr/bin</FILENAME>) and for data files, respectively. Next, consider a system that mostly runs as a compile-engine.</PARA>
<PARA>In this case, it might be best to place the <FILENAME>/tmp</FILENAME> directory on a disk separate from the source code being compiled. Make sure that you check and mount the filesystem before creating any files on it. (If this is not feasible, you can instruct the compiler to use a directory on another disk for temporary files. Just set the <LITERAL>TMPDIR</LITERAL> environment variable to the new directory for temporary files.) Now, look at a system that mainly runs many programs at the same time and does a lot of swapping.</PARA>
<PARA>In this case, it might be best to distribute the swap area in several partitions on different disks.</PARA>
</SECTION>
<SECTION><TITLE>About Adding Disk Hardware to Improve Disk I/O</TITLE><PARA>If improved I/O performance still does not occur after you have tuned your system, you may want to consider adding more hardware: disks, controllers, or memory.</PARA>
<PARA>If you are going to add more hardware to your system, how do you know which disk or controller to add? You can compare hardware specifications for currently supported disks and controllers by looking up the system specifications in your hardware owner's guide. By using this information, you can choose the right disk or controller to suit your particular needs.</PARA>
<PARA>By balancing the most active filesystems across controllers/disks, you can speed up disk access.</PARA>
<PARA>Another way to reduce the number of reads and writes that go out to the disk is to add more memory. This reduces swapping and paging.</PARA>
</SECTION>
</SECTION>
<SECTION  ID="LE70043-PARENT"><TITLE  ID="LE70043-TITLE">About Paging and Swapping</TITLE><PARA>The CPU can only reference data and execute code if the data or code are in the main memory (RAM). Because the CPU executes multiple processes, there may not be enough memory for all the processes. If you have very large programs, they may require more memory than is physically present in the system. So, processes are brought into memory in pages. If there is not enough memory, the operating system frees memory by writing pages temporarily to a secondary memory area, the swap area, on a disk.</PARA>
<PARA>IRIX overcommits real memory, loading and starting many more processes than can fit at one time into the available memory. Each process is given its own virtual section of memory, called its address space, which is theoretically large enough to contain the entire process. However, only those pages of the address space that are currently in use are actually kept in memory. These pages are called the working set. As the process needs new pages of data or code to continue running, the needed pages are read into main memory (called <FIRSTTERM>faulting in</FIRSTTERM> pages or <FIRSTTERM>page faults</FIRSTTERM>). If a page has not been used in the recent past, the operating system moves the page out of main memory and into the swap space to make room for new pages being faulted in. Pages written out can be faulted back in later. This process is called <FIRSTTERM>paging</FIRSTTERM>, and it should not be confused with the action of swapping.</PARA>
<PARA>Swapping is when all the pages of an inactive process are removed from memory to make room for pages belonging to active processes. The entire process is written out to the swap area on the disk and its execution effectively stops. When an inactive process becomes active again, its pages must be recovered from disk into memory before it can execute. This is called <FIRSTTERM>swapping in</FIRSTTERM> the process. On a personal workstation, swapping in is the familiar delay for disk activity, after you click on the icon of an inactive application and before its window appears.</PARA>
<SECTION><TITLE>Checking for Excessive Paging and Swapping</TITLE><PARA>When IRIX is multiprocessing a large number of processes, the amount of this swapping and paging activity can dominate the performance of the system. You can use the <COMMAND>sar</COMMAND> command to detect this condition and other tools to deal with it.</PARA>
<PARA>Determining whether your system is overloaded with paging and swapping requires some knowledge of a baseline. You need to use <COMMAND>sar</COMMAND> under various conditions to determine a baseline for your specific implementation. For example, you can boot your system and run some baseline tests with a limited number of processes running, and then again during a period of light use, a period of heavy networking activity, and then especially when the load is high and you are experiencing poor performance. Recording the results in your system log book can help you in making these baseline measurements. </PARA>
<PARA><XREF LINKEND="LE75788-TITLE"> shows indicators of excessive paging and swapping on a smaller system.</PARA><TABLE FRAME="topbot"><TBLTITLE  ID="LE75788-TITLE">Indicators of Excessive Swapping/Paging</TBLTITLE>
<TGROUP COLS="2">
<COLSPEC COLWIDTH="448*">
<COLSPEC COLWIDTH="128*">
<THEAD><ROW><ENTRY><PARA>Important Field</PARA></ENTRY>
<ENTRY><PARA>sar Option </PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA><LITERAL>vflt/s</LITERAL> - page faults (valid page not in memory)</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -p</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>bswot/s</LITERAL> (transfers from memory to disk swap area)</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -w</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>bswin/s</LITERAL> (transfers to memory)</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -w</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>%swpocc</LITERAL> (time swap queue is occupied)</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -q</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>rflt/s</LITERAL> (page man fault)</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -t</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>freemem</LITERAL> (average pages for user processes)</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -r</COMMAND></PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
<PARA>You can use the following <COMMAND>sar</COMMAND> options to determine if poor system performance is related to swap I/O or to other factors:</PARA>
<DEFLIST><DEFLISTENTRY><TERM><COMMAND>-u %wswp</COMMAND></TERM>
<LISTITEM><PARA>Percent of total I/O wait time owed to swap input. This measures the percentage of time during which active processes were blocked waiting for a page to be read or written. This number is not particularly meaningful unless the <LITERAL>wio</LITERAL> value is also high.</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><COMMAND>-p vflt/s</COMMAND></TERM>
<LISTITEM><PARA>Frequency with which a process accessed a page that was not in memory. Compare this number between times of good and bad performance. If the onset of poor performance is associated with a sharp increase of <LITERAL>vflt/s</LITERAL>, swap I/O may be a problem even if <LITERAL>%vswp</LITERAL> is low or 0.</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><COMMAND>-r freemem</COMMAND></TERM>
<LISTITEM><PARA>Unused memory pages. The paging daemon (<COMMAND>vhand</COMMAND>) recovers what it thinks are unused pages and returns them to this pool. When a process needs a fresh page, the page comes from this pool. If the pool is low or empty, IRIX often has to get a page for one process by taking a page from another process, encouraging further page faults.</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><COMMAND>-p pgswp/s</COMMAND></TERM>
<LISTITEM><PARA>Number of read/write data pages retrieved from the swap disk space per second.</PARA>
</LISTITEM>
</DEFLISTENTRY>
<DEFLISTENTRY><TERM><COMMAND>-p pgfil/s</COMMAND></TERM>
<LISTITEM><PARA>Number of read-only code pages retrieved from the disk per second.</PARA>
</LISTITEM>
</DEFLISTENTRY>
</DEFLIST>
<PARA>If the <LITERAL>%vswp</LITERAL> number is 0 or very low, and <LITERAL>vflt/s</LITERAL> does not increase with the onset of poor performance, the performance problem is not primarily due to swap I/O.</PARA>
</SECTION>
<SECTION><TITLE>Fixing Swap I/O Problems</TITLE><PARA>However, when swap I/O may be the cause, there are several possible actions you can take:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Provide more real memory. This is especially effective in personal workstations, where it is relatively economical to double the available real memory.</PARA>
</LISTITEM>
<LISTITEM><PARA>Reduce the demand for memory by running fewer processes. This can be effective when the system load is not interactive, but composed of batch programs or long-running commands. Schedule commands for low-demand hours, using <COMMAND>cron</COMMAND> and <COMMAND>at</COMMAND>. Experiment to find out whether the total execution time of a set of programs is less when they are run sequentially with low swap I/O, or concurrently with high swap I/O.</PARA>
</LISTITEM>
<LISTITEM><PARA>Make the swap input of read-only pages more effective. For example, if pages of dynamic shared objects are loaded from NFS-mounted drives over a slow network, you can make page input faster by moving all or a selection of dynamic shared objects to a local disk.</PARA>
</LISTITEM>
<LISTITEM><PARA>Make swap I/O of writable pages more effective. For example, use <COMMAND>swap(1M)</COMMAND> to spread swap activity across several disks or partitions. For more information on swapping to files and creating new swap areas, see <XREF LINKEND="LE23091-TITLE">..</PARA></LISTITEM>
<LISTITEM><PARA>If you have changed process or CPU-related kernel parameters (for example,<LITERAL>&ensp;nproc</LITERAL>), consider restoring them to their former values.</PARA>
</LISTITEM>
<LISTITEM><PARA>Reduce page faults. Construct programs with &ldquo;locality&rdquo; in mind (see <XREF LINKEND="LE80089-TITLE">).</PARA></LISTITEM>
<LISTITEM><PARA>Consider using shared libraries when constructing applications.</PARA>
</LISTITEM>
<LISTITEM><PARA>Reduce resident set size limits with <COMMAND>systune</COMMAND>. See <XREF LINKEND="LE88844-TITLE"> for the names and characteristics of the appropriate parameters.</PARA></LISTITEM>
</ITEMIZEDLIST>
<PARA>Refer to <XREF LINKEND="LE70628-PARENT"> for information on dynamic tuning of page size.</PARA></SECTION>
</SECTION>
<SECTION  ID="LE30287-PARENT"><TITLE  ID="LE30287-TITLE">CPU Activity and Memory Allocation</TITLE><PARA>After looking at disk I/O and paging for performance problems, check CPU activity and memory allocation.</PARA>
<SECTION><TITLE>Checking the CPU </TITLE><PARA>A CPU can execute only one process at any given instant. If the CPU becomes overloaded, processes have to wait instead of executing. You cannot change the speed of the CPU (although you may be able to upgrade to a faster CPU or add CPU boards to your system if your hardware allows it), but you can monitor CPU load and try to distribute it. <XREF LINKEND="LE53640-TITLE"> shows the fields to check for indications that a system is CPU bound.</PARA><TABLE FRAME="topbot"><TBLTITLE  ID="LE53640-TITLE">Indications of a CPU-Bound System</TBLTITLE>
<TGROUP COLS="3">
<COLSPEC COLWIDTH="512*">
<COLSPEC COLWIDTH="134*">
<COLSPEC COLWIDTH="142*">
<THEAD><ROW><ENTRY><PARA>Field</PARA></ENTRY>
<ENTRY><PARA>Value</PARA></ENTRY>
<ENTRY><PARA>sar Option </PARA></ENTRY>
</ROW>
</THEAD>
<TBODY><ROW><ENTRY><PARA><LITERAL>%idle</LITERAL> (% of time CPU has no work to do)</PARA></ENTRY>
<ENTRY><PARA>&lt;5</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -u</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>runq-sz</LITERAL> (processes in memory waiting for CPU)</PARA></ENTRY>
<ENTRY><PARA>&gt;2</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -q</COMMAND></PARA></ENTRY>
</ROW>
<ROW><ENTRY><PARA><LITERAL>%runocc</LITERAL> (% run queue occupied and processes not executing)</PARA></ENTRY>
<ENTRY><PARA>&gt;90</PARA></ENTRY>
<ENTRY><PARA><COMMAND>sar -q</COMMAND></PARA></ENTRY>
</ROW>
</TBODY>
</TGROUP>
</TABLE>
<PARA>You can also use the <COMMAND>top(1)</COMMAND> or <COMMAND>gr_top(1)</COMMAND> commands to display processes having the highest CPU usage. For each process, the output lists the user, process state flags, process ID and group ID, CPU cycles used, processor currently executing the process, process priority, process size (in pages), resident set size (in pages), amount of time used by the process, and the process name. For more information, see the <COMMAND>top(1)</COMMAND> or <COMMAND>gr_top(1)</COMMAND> man pages.</PARA>
</SECTION>
<SECTION><TITLE>Increasing CPU Performance</TITLE><PARA>To increase CPU performance, make the following modifications:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Off-load jobs to non-peak times or to another system, set efficient paths, and tune applications.</PARA>
</LISTITEM>
<LISTITEM><PARA>Eliminate polling loops (see <COMMAND>select(2)</COMMAND>).</PARA>
</LISTITEM>
<LISTITEM><PARA>Increase the <LITERAL>slice-size</LITERAL> parameter (the length of a process time slice). For example, change <LITERAL>slice-size</LITERAL> from Hz/30 to Hz/10. However, be aware that this may slow interactive response time.</PARA>
</LISTITEM>
<LISTITEM><PARA>Upgrade to a faster CPU or add another CPU.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
</SECTION>
<SECTION><TITLE>Checking Available Memory </TITLE><PARA><XREF LINKEND="LE70043-TITLE">, describes what happens when you do not have enough physical (main) memory for processes. This section discusses a different problem&mdash;what happens when you do not have enough available memory (sometimes called <FIRSTTERM>virtual memory</FIRSTTERM>), which includes both physical memory and logical swap space.</PARA>
<PARA>The IRIX virtual memory subsystem allows programs that are larger than physical memory to execute successfully. It also allows several programs to run even if the combined memory needs of the programs exceed physical memory. It does this by storing the excess data on the swap device(s).</PARA>
<PARA>The allocation of swap space is done after program execution has begun. This allows programs with large a virtual address to run as long as the actual amount of virtual memory allocated does not exceed the memory and swap resources of the machine.</PARA>
<PARA>Usually it is evident when you run out of memory, because a message is sent to the console that begins:</PARA>
<LITERALLAYOUT>
Out of logical swap space...
</LITERALLAYOUT>
<PARA>If you see this message these are the possible causes:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>The process has exceeded <LITERAL>ENOMEM</LITERAL> or <LITERAL>UMEM</LITERAL>.</PARA>
</LISTITEM>
<LISTITEM><PARA>There is not enough physical memory for the kernel to hold the required non-pageable data structures.</PARA>
</LISTITEM>
<LISTITEM><PARA>There is not enough logical swap space.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>You can add virtual swap space to your system at any time. See <XREF LINKEND="LE23091-TITLE">. to add more swap space. You need to add physical swap space, though, if you see the message:</PARA><LITERALLAYOUT>
Process killed due to insufficient memory
</LITERALLAYOUT>
<PARA>The following system calls return <LITERAL>EAGAIN</LITERAL> if there is insufficient available memory: <COMMAND>exec</COMMAND>, <COMMAND>fork</COMMAND>, <COMMAND>brk</COMMAND>, <COMMAND>sbrk</COMMAND> (called by <COMMAND>malloc</COMMAND>), <COMMAND>mpin</COMMAND>, and <COMMAND>plock</COMMAND>. Applications should check the return status and exit gracefully with a useful message.</PARA>
<PARA>To check the size (in pages) of a process that is running, execute <COMMAND>ps -el</COMMAND> (you can also use <COMMAND>top</COMMAND>). The <LITERAL>SZ:RSS</LITERAL> field shows very large processes.</PARA>
<PARA>By checking this field, you can determine the amount of memory the process is using. A good strategy is to run very large processes at less busy times.</PARA>
</SECTION>
<SECTION><TITLE>Determining the Amount of System Memory </TITLE><PARA>To see the amount of main memory, use the <COMMAND>hinv(1)</COMMAND> command. It displays data about your system's configuration. For example:</PARA>
<PROGRAMLISTING>
<LITERAL>Main memory size: 64 Mb</LITERAL>
</PROGRAMLISTING>
</SECTION>
<SECTION><TITLE>Maximizing Memory </TITLE><PARA>To increase the amount of virtual memory, increase the amount of real memory and/or swap space. Note that most of the paging/swapping solutions are also ways to conserve available memory. These include:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Limiting the number of programs </PARA>
</LISTITEM>
<LISTITEM><PARA>Using shared libraries </PARA>
</LISTITEM>
<LISTITEM><PARA>Adding more memory </PARA>
</LISTITEM>
<LISTITEM><PARA>Decreasing the size of system tables</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>However, the most dramatic way to increase the amount of virtual memory is to add more swap space. See <XREF LINKEND="LE23091-TITLE">..</PARA></SECTION>
</SECTION>
</SECTION>
<SECTION  ID="LE10876-PARENT"><TITLE  ID="LE10876-TITLE">Operating System Tuning</TITLE><PARA>The process of tuning the operating system is not difficult, but it should be approached carefully. Make complete notes of your actions in case you need to reverse your changes later on. Understand what you are going to do before you do it, and do not expect miraculous results; IRIX has been engineered to provide the best possible performance under all but the most extreme conditions. Software that provides a great deal of graphics manipulation or data manipulation also carries a great deal of overhead for the system, and can seriously affect the speed of an otherwise robust system. No amount of tuning can change these situations.</PARA>
<SECTION  ID="LE80028-PARENT"><TITLE  ID="LE80028-TITLE">Operating System Tuning Procedure</TITLE><PARA>To tune a system, you first monitor its performance with various system utilities as described in <XREF LINKEND="LE11632-TITLE">.. <XREF LINKEND="LE19177-TITLE"> describes the steps to take when you are tuning a system.</PARA><PROCEDURE  ID="LE19177-PARENT"><TITLE  ID="LE19177-TITLE">Tuning a System</TITLE>
<STEP><PARA>Determine the general area that needs tuning (for example, disk I/O or the CPU) and monitor system performance using utilities such as <COMMAND>sar</COMMAND> and <COMMAND>osview</COMMAND>. If you have not already done so, see <XREF LINKEND="LE11632-TITLE">..</PARA></STEP>
<STEP><PARA>Pinpoint a specific area and monitor performance over a period of time. Look for numbers that show large fluctuation or change over a sustained period; do not be too concerned if numbers occasionally go beyond the maximum.</PARA>
</STEP>
<STEP><PARA>Modify one value/characteristic at a time (for example, change a parameter, add a controller) to determine its effect. It is good practice to document any changes in a system notebook.</PARA>
</STEP>
<STEP><PARA>Use the <COMMAND>systune</COMMAND> command to change parameter values or make the change in the <FILENAME>master.d</FILENAME> directory structure if the variable is not tunable through <COMMAND>systune</COMMAND>. Remake the kernel and reboot if necessary.</PARA>
</STEP>
<STEP><PARA>Remeasure performance and compare the before and after results. Then evaluate the results (is system performance better?) and determine whether further change is needed.</PARA>
</STEP>
</PROCEDURE>
<PARA>Keep in mind that the tuning procedure is more an art than a science; you may need to repeat the above steps as necessary to fine tune your system. You may find that you will need to do more extensive monitoring and testing to thoroughly fine-tune your system. </PARA>
</SECTION>
<SECTION><TITLE>Operating System Tuning: Finding Parameter Values</TITLE><PARA>Before you can tune your system, you need to know the current values of the tunable parameters. To find the current value of your kernel parameters, use the <COMMAND>systune</COMMAND> command. This command, entered with no arguments, prints the current values of all tunable parameters on your system. For complete information on this command, see the <COMMAND>systune(1M)</COMMAND> man page.</PARA>
</SECTION>
<SECTION  ID="LE86996-PARENT"><TITLE  ID="LE86996-TITLE">Operating System Tuning: Changing Parameters and Reconfiguring the System</TITLE><PARA>After determining the parameter or parameters to adjust, you must change the parameters and you may need to reconfigure the system for the changes to take effect. The <COMMAND>systune </COMMAND>utility tells you when you make parameter changes if you must reboot to activate those changes. <XREF LINKEND="LE16719-TITLE"> describes the steps you take to reconfigure a system.</PARA><PROCEDURE  ID="LE16719-PARENT"><TITLE  ID="LE16719-TITLE">Reconfiguring a System</TITLE>
<STEP><PARA>Back up the system.</PARA>
</STEP>
<STEP><PARA>Copy your existing kernel to <FILENAME>unix.save</FILENAME>. </PARA>
</STEP>
<STEP><PARA>Make your changes.</PARA>
</STEP>
<STEP><PARA>Reboot your system, if necessary.</PARA>
</STEP>
</PROCEDURE>
<SECTION><TITLE>Backing Up the System </TITLE><PARA>Before you reconfigure the system by changing kernel parameters, it is a good idea to have a current and complete backup of the system. See the <CITETITLE><LINK BOOK="IA_BakSecAcc" EXTREF="70848">IRIX Admin: Backup, Security, and Accounting</LINK>
</CITETITLE> guide.</PARA>
<CAUTION><PARA>Always back up the entire system before tuning.</PARA>
</CAUTION>
</SECTION>
<SECTION><TITLE>Copying the Kernel</TITLE><PARA>After determining the parameter you need to change (for example, you need to increase <REPLACEABLE>nproc</REPLACEABLE> because you have a large number of users), you must first back up the system and the kernel. Give the command:</PARA>
<LITERALLAYOUT>
<USERINPUT>cp /unix /unix.save</USERINPUT>
</LITERALLAYOUT>
<PARA>This command creates a safe copy of your kernel. Through the rest of this example, this is called your old saved kernel. If you make this copy, you can always go back to your old saved kernel if you are not satisfied with the results of your tuning.</PARA>
</SECTION>
<SECTION><TITLE>Changing a Parameter </TITLE><PARA>Once your backups are complete, you can execute the <COMMAND>systune</COMMAND> command. Note that you can present new values to <COMMAND>systune</COMMAND> in either hexadecimal or decimal notation. Both values are printed by <COMMAND>systune</COMMAND>.</PARA>
<PARA>An invocation of <COMMAND>systune</COMMAND> to increase <LITERAL>nproc</LITERAL> looks something like this:</PARA>
<LITERALLAYOUT>
<USERINPUT>systune -i</USERINPUT>
Updates will be made to running system and /unix.install
systune-&gt; <USERINPUT>nproc</USERINPUT>
&ensp;       nproc = 400 (0x190)
systune-&gt; <USERINPUT>nproc = 500</USERINPUT>
&ensp;       nproc = 400 (0x190)
&ensp;       Do you really want to change nproc to 500 (0x1f4)? (y/n) <USERINPUT>y</USERINPUT>
In order for the change in parameter nproc to become effective /unix.install must be moved to /unix and the system rebooted
systune-&gt; <USERINPUT>quit</USERINPUT>
</LITERALLAYOUT>
<PARA>Then reboot your system. Also, be sure to document the parameter change you made in your system log book.</PARA>
<CAUTION><PARA>When you issue the <COMMAND>reboot</COMMAND> command, the system overwrites the current kernel (<FILENAME>/unix</FILENAME>) with the kernel you have just created (<FILENAME>/unix.install</FILENAME>). This is why you should always copy the current kernel to a safe place before rebooting.</PARA>
</CAUTION>
</SECTION>
<SECTION><TITLE>Creating and Booting a New Kernel with autoconfig</TITLE><PARA>The <COMMAND>systune</COMMAND> command creates a new kernel automatically. However, if you changed parameters without using <COMMAND>systune</COMMAND>, or if you have added new system hardware (such as a new CPU board on a multiprocessor system), you must use <COMMAND>autoconfig</COMMAND> to generate a new kernel.</PARA>
<PARA>The <COMMAND>autoconfig</COMMAND> command uses some environment variables. These variables are described in detail in the <COMMAND>autoconfig(1M)</COMMAND> man page. If you have any of the following variables set, you may need to unset them before running <COMMAND>autoconfig</COMMAND>:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA><LITERAL>UNIX</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>SYSGEN</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>BOOTAREA</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>SYSTEM</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>MASTERD</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>STUNEFILE</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>MTUNEDIR</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>WORKDIR</LITERAL></PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>To build a new kernel after reconfiguring the system, follow the steps in <XREF LINKEND="LE37479-TITLE">:</PARA><PROCEDURE  ID="LE37479-PARENT"><TITLE  ID="LE37479-TITLE">Building a New Kernel</TITLE>
<STEP><PARA>Become the superuser by giving the command:</PARA>
<PROGRAMLISTING>
<USERINPUT>su</USERINPUT>
</PROGRAMLISTING>
</STEP>
<STEP><PARA>Make a copy of your current kernel with the command:</PARA>
<LITERALLAYOUT>
<USERINPUT>cp /unix /unix.save</USERINPUT>
</LITERALLAYOUT>
</STEP>
<STEP><PARA>Give the command:</PARA>
<LITERALLAYOUT>
<USERINPUT>/etc/autoconfig -f</USERINPUT>
</LITERALLAYOUT>
<PARA>This command creates a new kernel and places it in the file <FILENAME>/unix.install</FILENAME>.</PARA>
</STEP>
<STEP><PARA>Reboot your system with the command:</PARA>
<LITERALLAYOUT>
<USERINPUT>reboot</USERINPUT>
</LITERALLAYOUT>
<CAUTION><PARA>When you issue the <COMMAND>reboot</COMMAND> command, the system overwrites the current kernel (<FILENAME>/unix</FILENAME>) with the kernel you have just created (<FILENAME>/unix.install</FILENAME>). This is why you should always copy the current kernel to a safe place before rebooting.</PARA>
</CAUTION>
</STEP>
</PROCEDURE>
<PARA>An autoconfiguration script, found in <FILENAME>/etc/rc2.d/S95autoconfig</FILENAME>, runs during system startup. This script asks you if you would like to build a new kernel under the following conditions:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>A new board has been installed for which no driver exists in the current kernel.</PARA>
</LISTITEM>
<LISTITEM><PARA>There have been changes to object files in <FILENAME>/var/sysgen/mtune</FILENAME>, master files in <FILENAME>/var/sysgen/master.d</FILENAME>, or the system files in <FILENAME>/var/sysgen/system</FILENAME>. This is determined by the modification dates on these files and the kernel.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>If any of these conditions is true, the system prompts you during startup to reconfigure the operating system:</PARA>
<LITERALLAYOUT>
Automatically reconfigure the operating system? y
</LITERALLAYOUT>
<PARA>If you answer <USERINPUT>y</USERINPUT> to the prompt, the script runs <COMMAND>lboot</COMMAND> and generates <FILENAME>/unix.install</FILENAME> with the new image.You can disable the autoconfiguration script by renaming <FILENAME>/etc/rc2.d/S95autoconfig</FILENAME> to something else that does not begin with the letter <LITERAL>S</LITERAL>, for example, <FILENAME>/etc/rc2.d/wasS95autoconfig</FILENAME>.</PARA>
</SECTION>
</SECTION>
</SECTION>
<SECTION  ID="LE34306-PARENT"><TITLE  ID="LE34306-TITLE">Recovering from an Unbootable Kernel </TITLE><PARA><XREF LINKEND="LE33907-TITLE"> explains how to recover from an unbootable <FILENAME>/unix</FILENAME>, and describes how to get a viable version of the software running after an unsuccessful reconfiguration attempt. If you use the <COMMAND>systune</COMMAND> utility, you should never have to use this information, since <COMMAND>systune</COMMAND> does not allow you to set your parameters to unworkable values.</PARA>
<PROCEDURE  ID="LE33907-PARENT"><TITLE  ID="LE33907-TITLE">Recovering from an Unbootable Kernel</TITLE>
<STEP><PARA>If the system fails to reboot, try to reboot it again. If it still fails, interrupt the boot process and direct the boot PROM to boot from your old saved kernel (<FILENAME>unix.save</FILENAME>). </PARA>
</STEP>
<STEP><PARA>Press the <KEYCAP>Reset</KEYCAP> button.You see the <INTERFACE>System Maintenance Menu</INTERFACE>:</PARA>
<LITERALLAYOUT>
System Maintenance Menu
</LITERALLAYOUT>
<PROGRAMLISTING>
1) Start System.
2) Install System Software.
3) Run Diagnostics.
4) Recover System.
5) Enter Command Monitor.
</PROGRAMLISTING>
</STEP>
<STEP><PARA>Choose option 5 to enter the command monitor. You see:</PARA>
<PROGRAMLISTING>
Command Monitor. Type "exit" to return to the menu.
&gt;&gt;
</PROGRAMLISTING>
</STEP>
<STEP><PARA>Now at the <LITERAL>&gt;&gt;</LITERAL> prompt, tell the PROM to boot your old saved kernel. The command is:</PARA>
<LITERALLAYOUT>
<USERINPUT>boot unix.save</USERINPUT>
</LITERALLAYOUT>
<PARA>The system boots the old saved kernel.</PARA>
</STEP>
<STEP><PARA>Once the system is running, use the following command to move your old saved kernel to the default <FILENAME>/unix</FILENAME> name. This method also keeps a copy of your old saved kernel in <FILENAME>unix.save</FILENAME>:</PARA>
<LITERALLAYOUT>
<USERINPUT>cp /unix.save /unix</USERINPUT>
</LITERALLAYOUT>
</STEP>
</PROCEDURE>
<PARA>Then you can normally boot the system while you investigate the problem with the new kernel. Try to figure out what went wrong. What was changed that stopped the kernel from booting? Review the changes that you made.</PARA>
<ITEMIZEDLIST><LISTITEM><PARA>Did you increase/decrease a parameter by a large amount? If so, make the change less drastic.</PARA>
</LISTITEM>
<LISTITEM><PARA>Did you change more than one parameter? If so, make a change to only one parameter at a time.</PARA>
</LISTITEM>
</ITEMIZEDLIST>
</SECTION>
<SECTION  ID="LE70628-PARENT"><TITLE  ID="LE70628-TITLE">Multiple Page Sizes</TITLE><PARA>The operating system supports multiple page sizes, which can be tuned as described in this section.</PARA>
<SECTION><TITLE>Recommended Page Sizes</TITLE><PARA>The page sizes supported depend on the base page size of the system. The base page size can be obtained by using the <COMMAND>getpagesize()</COMMAND> system call. Currently IRIX supports two base page sizes, 16K and 4K. On systems with 16K base page size the following tunable page sizes are supported, 16K, 64K, 256K, 1M, 4M, 16M. On systems with 4K base page size, the following tunable page sizes are supported, 4K, 16K, 256K, 1M, 4M, 16M. In general for most applications 4K, 16K, and 64K page sizes are sufficient to eliminate tlbmiss overhead.</PARA>
</SECTION>
<SECTION><TITLE>Tunable Parameters for Coalescing</TITLE><PARA>The IRIX kernel tries to keep a percentage of total free memory in the system at a certain page size. It periodically tries to coalesce a group of adjacent pages to form a large page. The following tunable parameters specify the upper limit for the number of free pages at a particular page size. Systems that do not need large pages can set these parameters to zero. The tunable parameters are:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA><LITERAL>percent_totalmem_16k_pages</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>percent_totalmem_64k_pages</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>percent_totalmem_256k_pages</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>percent_totalmem_1m_pages</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>percent_totalmem_4m_pages</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>percent_totalmem_16m_pages</LITERAL></PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>The parameters specify the percentage of total memory that can be used as an upper limit for the number of pages in a specific page size. Thus setting <LITERAL>percent_totalmem_64k_pages</LITERAL> to 20 implies that the coalescing mechanism tries to limit the number of free 64K pages to 20% of total memory in the system. These parameters can be tuned dynamically at run time. Note that very large pages (&gt;= 1&nbsp;MB) are harder to coalesce dynamically during run time on a busy system. It is recommended these tunable parameters be set during boot time in such cases. Setting these tunable parameters to a high value can result in high coalescing activity. If the system runs low on memory, the large pages can be split into smaller pages as needed.</PARA>
</SECTION>
<SECTION><TITLE>Reserving Large Pages</TITLE><PARA>It is hard to coalesce very large pages (&gt;= 1&nbsp;MB) at run time due to fragmentation of physical memory. Applications that need such pages can set tunable parameters to reserve large pages during boot time. They are specified as the number of pages. The tunable parameters are:</PARA>
<ITEMIZEDLIST><LISTITEM><PARA><LITERAL>nlpages_64k</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>nlpages_256k</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>nlpages_1m</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>nlpages_4m</LITERAL></PARA>
</LISTITEM>
<LISTITEM><PARA><LITERAL>nlpages_16m</LITERAL></PARA>
</LISTITEM>
</ITEMIZEDLIST>
<PARA>Thus setting <LITERAL>nlpages_4m</LITERAL> to 4 results in the system reserving four 4&nbsp;MB pages during boot time. If the system runs low on memory, the reserved pages can be split into smaller pages for use by other applications. The command <COMMAND>osview</COMMAND> can be used to view the number of free pages available at a particular page size (see <COMMAND>osview(1)</COMMAND>). The default value for all these parameters is zero. Refer to <XREF LINKEND="LE85610-PARENT"> for additional information.</PARA></SECTION>
</SECTION>
</CHAPTER>
