<!-- Produced by version 3.14 (11/22/96) of SGI Frame/SGML translator -->
<CHAPTER LBL="6"><TITLE><XREFTARGET ID="68928">Troubleshooting&nbsp;ONC3/NFS</TITLE><PARAGRAPH>This chapter suggests strategies for troubleshooting the ONC3/NFS environment, including automatic mounting. This chapter contains these sections:</PARAGRAPH>
<BULLETLIST><BULLET><PARAGRAPH><XREF IDREF="92453" TYPE="TITLE">&ldquo;General Recommendations&rdquo;</XREF></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><XREF IDREF="67767" TYPE="TITLE">&ldquo;Understanding the Mount Process&rdquo;</XREF></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><XREF IDREF="36456" TYPE="TITLE">&ldquo;Identifying the Point of Failure&rdquo;</XREF></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><XREF IDREF="34000" TYPE="TITLE">&ldquo;Troubleshooting NFS Common Failures&rdquo;</XREF></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><XREF IDREF="92032" TYPE="TITLE">&ldquo;Troubleshooting automount&rdquo;</XREF></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><XREF IDREF="52624" TYPE="TITLE">&ldquo;Troubleshooting autofs&rdquo;</XREF></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><XREF IDREF="29475" TYPE="TITLE">&ldquo;Troubleshooting CacheFS&rdquo;</XREF></PARAGRAPH>
</BULLET>
</BULLETLIST>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="92453">General Recommendations</TITLE><PARAGRAPH>If you experience difficulties with ONC3/NFS, review the ONC3/NFS documentation before trying to debug the problem. In addition to this guide, the ONC3/NFS <INDEXTARGET ID="nfsch61"><!-- POSTPROCESSDATA: nfsch61|troubleshooting recommendations --><DOCTITLE>Release Notes</DOCTITLE> and the reference pages for <REFPAGE>mount(1M)</REFPAGE>, <REFPAGE>nfsd(1M)</REFPAGE>, <REFPAGE>showmount(1M)</REFPAGE>, <REFPAGE>exportfs(1M)</REFPAGE>, <REFPAGE>rpcinfo(1M)</REFPAGE>, <REFPAGE>mountd(1M)</REFPAGE>, <REFPAGE>inetd(1M)</REFPAGE>, <REFPAGE>fstab(4)</REFPAGE>, <REFPAGE>mtab(4)</REFPAGE>, <REFPAGE>lockd(1M)</REFPAGE>, <REFPAGE>statd(1M)</REFPAGE>, <REFPAGE>automount(1M)</REFPAGE>, <REFPAGE>autofs(1M)</REFPAGE>, and <REFPAGE>exports(4)</REFPAGE> contain information you should review. You do not have to understand them fully, but be familiar with the names and functions of relevant daemons and database files.</PARAGRAPH>
<PARAGRAPH>Be sure to check the console and <INDEXTARGET ID="nfsch62"><!-- POSTPROCESSDATA: nfsch62|<ITALICS>/var/adm/SYSLOG</ITALICS> file --><FILENAME>/var/adm/SYSLOG</FILENAME> for messages about ONC3/NFS or other activity that affects ONC3/NFS performance. Logged messages frequently provide information that helps explain problems and assists with troubleshooting.</PARAGRAPH>
</SECTION1>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="67767">Understanding the Mount Process</TITLE><PARAGRAPH>This section explains the interaction of the various players in the <INDEXTARGET ID="nfsch63"><!-- POSTPROCESSDATA: nfsch63|<ITALICS>mount</ITALICS> command:mount process description --><INDEXTARGET ID="nfsch64"><!-- POSTPROCESSDATA: nfsch64|mounting:process description --><COMMAND>mount</COMMAND> request. If you understand this interaction, the problem descriptions in this chapter will make more sense. Here is a sample <COMMAND>mount</COMMAND> request: </PARAGRAPH>
<CODE>
<USERINPUT>mount krypton:/usr/src /n/krypton.src</USERINPUT>
</CODE>
<PARAGRAPH>These are the steps <COMMAND>mount</COMMAND> goes through to mount a remote filesystem:</PARAGRAPH>
<ORDEREDLIST><LIST><PARAGRAPH><INDEXTARGET ID="nfsch65"><!-- POSTPROCESSDATA: nfsch65|<ITALICS>/etc/fstab</ITALICS> file --><COMMAND>mount</COMMAND> parses <FILENAME>/etc/fstab</FILENAME>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><COMMAND>mount</COMMAND> checks to see if the caller is the superuser and if <FILENAME>/n/krypton.src</FILENAME> is a directory.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><INDEXTARGET ID="nfsch66"><!-- POSTPROCESSDATA: nfsch66|<ITALICS>/etc/mtab</ITALICS> file --><COMMAND>mount</COMMAND> opens <FILENAME>/etc/mtab</FILENAME> and checks that this mount has not already been done.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><COMMAND>mount</COMMAND> parses the first argument into the system <ITALICS>krypton</ITALICS> and remote directory <FILENAME>/usr/src</FILENAME>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><INDEXTARGET ID="nfsch67"><!-- POSTPROCESSDATA: nfsch67|IP address translation --><INDEXTARGET ID="nfsch68"><!-- POSTPROCESSDATA: nfsch68|<ITALICS>/usr/etc/resolv.conf</ITALICS> file --><INDEXTARGET ID="nfsch69"><!-- POSTPROCESSDATA: nfsch69|NIS:databases --><COMMAND>mount</COMMAND> calls library routines to translate the host name (<ITALICS>krypton</ITALICS>) to its Internet Protocol (IP) address. Tis hostname resolution will be performed using the Unified Name Services defined in <FILENAME>/etc/nsswitch.conf</FILENAME>. See <REFPAGE>nsswitch.conf(4)</REFPAGE>. </PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><INDEXTARGET ID="nfsch610"><!-- POSTPROCESSDATA: nfsch610|portmapper --><COMMAND>mount</COMMAND> calls <ITALICS>krypton</ITALICS>'s<ITALICS>&space;portmap </ITALICS>daemon to get the port number of <ITALICS>mountd</ITALICS>. See <REFPAGE>portmap(1M)</REFPAGE>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><COMMAND>mount</COMMAND> calls <ITALICS>krypton</ITALICS>'s <COMMAND>mountd</COMMAND> and passes it <FILENAME>/usr/src</FILENAME>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><ITALICS>krypton</ITALICS>'s <COMMAND>mountd</COMMAND> reads <FILENAME>/etc/exports</FILENAME> and looks for the exported filesystem that contains <FILENAME>/usr/src</FILENAME>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><ITALICS>krypton</ITALICS>'s <COMMAND>mountd</COMMAND> calls library routines to expand the hostnames and network groups in the export list for <FILENAME>/usr/src</FILENAME>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><ITALICS>krypton</ITALICS>'s <COMMAND>mountd</COMMAND> performs a system call on <FILENAME>/usr/src</FILENAME> to get the file handle.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><ITALICS>krypton</ITALICS>'s <COMMAND>mountd</COMMAND> returns the file handle.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><COMMAND>mount</COMMAND> does a <COMMAND>mount</COMMAND> system call with the file handle and <FILENAME>/n/krypton.src</FILENAME>.</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><COMMAND>mount</COMMAND> does a <COMMAND>statfs </COMMAND>call to <ITALICS>krypton</ITALICS>'s NFS server (<COMMAND>nfsd</COMMAND>).</PARAGRAPH>
</LIST>
<LIST><PARAGRAPH><COMMAND>mount</COMMAND> opens <FILENAME>/etc/mtab</FILENAME> and adds an entry to the end.</PARAGRAPH>
</LIST>
</ORDEREDLIST>
<PARAGRAPH>Any of these steps can fail, some of them in more than one way. </PARAGRAPH>
</SECTION1>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="36456">Identifying the Point of Failure</TITLE><PARAGRAPH>When analyzing an NFS problem, keep in mind that NFS, like all network services, has three main points of failure: the server, the client, and the network itself. The debugging strategy outlined below isolates each individual component to find the one that is not working.</PARAGRAPH>
<SECTION2 LBL="" HELPID = ""><TITLE>Verifying Server Status</TITLE><PARAGRAPH>If a client is having NFS trouble, check first to make sure the server is up and running. From a client, give this command:<INDEXTARGET ID="nfsch611"><!-- POSTPROCESSDATA: nfsch611|failure:of server --><INDEXTARGET ID="nfsch612"><!-- POSTPROCESSDATA: nfsch612|<ITALICS>rpcinfo</ITALICS> command --></PARAGRAPH>
<CODE>
<USERINPUT>/usr/etc/rpcinfo &ndash;p</USERINPUT>&space;<VARIABLE>server_name</VARIABLE>&space;<USERINPUT>| grep mountd</USERINPUT>
</CODE>
<PARAGRAPH>This checks whether the server is running. If the server is running, this command displays a list of programs, versions, protocols, and port numbers similar to this:</PARAGRAPH>
<CODE>
100005    1   tcp   1035  mountd
100005    1   udp   1033  mountd
391004    1   tcp   1037  sgi_mountd
391004    1   udp   1034  sgi_mountd
</CODE>
<PARAGRAPH>If the <INDEXTARGET ID="nfsch613"><!-- POSTPROCESSDATA: nfsch613|<ITALICS>sgi_mountd</ITALICS> daemon --><COMMAND>mountd</COMMAND> server is running, use <COMMAND>rpcinfo</COMMAND> to check if the <COMMAND>mountd</COMMAND> server is ready and waiting for mount requests by using the program number and version for <COMMAND>sgi_mountd</COMMAND> returned above. Give this command:</PARAGRAPH>
<CODE>
<USERINPUT>/usr/etc/rpcinfo &ndash;u</USERINPUT>&space;<VARIABLE>server_name</VARIABLE>&space;<USERINPUT>391004 1</USERINPUT>
</CODE>
<PARAGRAPH>The system responds:</PARAGRAPH>
<CODE>
program 391004 version 1 ready and waiting
</CODE>
<PARAGRAPH>If these fail, log in to the server and check its <FILENAME>/var/adm/SYSLOG</FILENAME> for messages.</PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Verifying Client Status</TITLE><PARAGRAPH>If the server and the network are working, give the command <INDEXTARGET ID="nfsch614"><!-- POSTPROCESSDATA: nfsch614|failure:of client --><USERINPUT>ps &ndash;de</USERINPUT> to check your client daemons. <COMMAND>inetd</COMMAND>, <COMMAND>routed</COMMAND>, <COMMAND>portmap</COMMAND>,&space;and four <COMMAND>biod</COMMAND> and <COMMAND>nfsd</COMMAND> daemons should be running. For example, the command<USERINPUT>&space;ps &ndash;de</USERINPUT> produces output similar to this:</PARAGRAPH>
<CODE>
&space;  PID TTY      TIME COMD
&space;  103 ?        0:46 routed
&space;  108 ?        0:01 portmap
&space;  136 ?        0:00 nfsd
&space;  137 ?        0:00 nfsd
&space;  138 ?        0:00 nfsd
&space;  139 ?        0:00 nfsd
&space;  142 ?        0:00 biod
&space;  143 ?        0:00 biod
&space;  144 ?        0:00 biod
&space;  145 ?        0:00 biod
&space;  159 ?        0:03 inetd
</CODE>
<PARAGRAPH>If the daemons are not running on the client, check <FILENAME>/var/adm/SYSLOG</FILENAME>, and ensure that <CMDLINEOPT>network</CMDLINEOPT> and <CMDLINEOPT>nfs</CMDLINEOPT><COMMAND>&space;chkconfig</COMMAND> flags are <CMDLINEOPT>on</CMDLINEOPT>. Rebooting the client almost always clears the problem. </PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Verifying Network Status</TITLE><PARAGRAPH>If the server is operative but your system cannot reach it, check the network connections between your system and the server and check <INDEXTARGET ID="nfsch615"><!-- POSTPROCESSDATA: nfsch615|failure:of network --><FILENAME>/var/adm/SYSLOG</FILENAME>. Visually inspect your network connection. You can also test the logical network connection with various network tools like <COMMAND>ping</COMMAND>. You can also check other systems on your network to see if they can reach the server.</PARAGRAPH>
</SECTION2>
</SECTION1>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="34000">Troubleshooting NFS Common Failures</TITLE><PARAGRAPH>The sections below describe the most common types of NFS failures. They suggest what to do if your remote mount fails, and what to do when servers do not respond to valid mount requests. <INDEXTARGET ID="nfsch616"><!-- POSTPROCESSDATA: nfsch616|mounting:remote mount failed --><INDEXTARGET ID="nfsch617"><!-- POSTPROCESSDATA: nfsch617|failure:of remote mount --><INDEXTARGET ID="nfsch618"><!-- POSTPROCESSDATA: nfsch618|hard-mounted filesystems --><INDEXTARGET ID="nfsch619"><!-- POSTPROCESSDATA: nfsch619|soft-mounted filesystems --><INDEXTARGET ID="nfsch620"><!-- POSTPROCESSDATA: nfsch620|mounting:hard mounts --></PARAGRAPH>
<SECTION2 LBL="" HELPID = ""><TITLE>Troubleshooting Mount Failure</TITLE><PARAGRAPH>When network or server problems occur, programs that access hard-mounted remote files fail differently from those that access soft-mounted remote files. Hard-mounted remote filesystems cause programs to continue to try until the server responds again. Soft-mounted remote filesystems return an error message after trying for a specified number of intervals. See <REFPAGE>fstab(4)</REFPAGE> for more information.</PARAGRAPH>
<PARAGRAPH>Programs that access hard-mounted filesystems do not respond until the server responds. In this case, NFS displays this message both to the console window and to the system log file <FILENAME>/var/adm/SYSLOG</FILENAME>:</PARAGRAPH>
<CODE>
server not responding
</CODE>
<PARAGRAPH>On a soft-mounted filesystem, programs that access a file whose server is inactive get the message:</PARAGRAPH>
<CODE>
Connection timed out
</CODE>
<PARAGRAPH>Unfortunately, many IRIX programs do not check return conditions on filesystem operations, so this error message may not be displayed when accessing soft-mounted files. Nevertheless, an NFS error message is displayed on the console.</PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Troubleshooting Lack of Server Response</TITLE><PARAGRAPH>If programs stop responding while doing file-related work, your NFS server may be inactive. You may see the message:</PARAGRAPH>
<CODE>
NFS server <VARIABLE>host_name</VARIABLE> not responding, still trying
</CODE>
<PARAGRAPH>The message includes the host name of the NFS server that is down. This is probably a problem either with one of your NFS servers or with the network hardware. Attempt to <INDEXTARGET ID="nfsch621"><!-- POSTPROCESSDATA: nfsch621|hanging --><COMMAND>ping</COMMAND> and <COMMAND>rlogin </COMMAND>to the server to determine whether the server is down. If you can successfully <COMMAND>rlogin</COMMAND> to the server, its NFS server function is probably disabled. </PARAGRAPH>
<PARAGRAPH>Programs can also hang if an NIS server becomes inactive. </PARAGRAPH>
<PARAGRAPH>If your system hangs completely, check the servers from which you have file systems mounted. If one or more of them is down, it is not cause for concern. If you are using hard mounts, your programs will continue automatically when the server comes back up, as if the server had not become inactive. No files are destroyed in such an event.</PARAGRAPH>
<PARAGRAPH>If a soft-mounted server is inactive, other work should not be affected. Programs that timeout trying to access soft-mounted remote files fail, but you should still be able to use your other filesystems.</PARAGRAPH>
<PARAGRAPH>If all of the servers are running, ask some other users of the same NFS server or servers if they are having trouble. If more than one client is having difficulty getting service, then the problem is likely with the server's NFS daemon <ITALICS>nfsd</ITALICS>. Log in to the server and give the command <USERINPUT>ps &ndash;de</USERINPUT> to see if <ITALICS>nfsd</ITALICS> is running and accumulating CPU time. If not, you may be able to kill and then restart <ITALICS>nfsd</ITALICS>. If this does not work, reboot the server.</PARAGRAPH>
<PARAGRAPH>If other people seem to be able to use the server, check your network connection and the connection of the server. </PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Troubleshooting Remote Mount Failure</TITLE><PARAGRAPH>If your workstation mounts local file systems after a boot but hangs when it normally would be doing remote mounts, one or more servers may be down or your network connection may be bad. This problem can be avoided entirely by using the background(<CMDLINEOPT>bg</CMDLINEOPT>) option to <COMMAND>mount</COMMAND> in <FILENAME>/etc/fstab</FILENAME> (see <REFPAGE>fstab(4)</REFPAGE>).&space;</PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Troubleshooting Slow Performance</TITLE><PARAGRAPH>If access to remote files seems unusually slow, give this command on the server:<INDEXTARGET ID="nfsch622"><!-- POSTPROCESSDATA: nfsch622|performance is slow --></PARAGRAPH>
<CODE>
<USERINPUT>ps &ndash;de</USERINPUT>
</CODE>
<PARAGRAPH>Check whether the server is being slowed by a runaway daemon. If the server seems to be working and other people are getting good response, make sure your block I/O daemons are running. </PARAGRAPH>
<NOTE><PREFIX>Note</PREFIX>The following text describes NFS version 2 on clients. NFS version 3 uses <COMMAND>bio3d</COMMAND>.</NOTE>
<PARAGRAPH>To check block I/O daemons, give this command on the client:</PARAGRAPH>
<CODE>
<USERINPUT>ps &ndash;de | grep biod</USERINPUT>
</CODE>
<PARAGRAPH>This command helps you determine whether processes are hung. Note the current accumulated CPU time, then copy a large remote file and again give this command:<INDEXTARGET ID="nfsch623"><!-- POSTPROCESSDATA: nfsch623|<ITALICS>biod</ITALICS> daemon --></PARAGRAPH>
<CODE>
<USERINPUT>ps &ndash;de | grep biod</USERINPUT>
</CODE>
<PARAGRAPH>If there are no <ITALICS>biod</ITALICS>s running, restart the processes by giving this command:</PARAGRAPH>
<CODE>
<USERINPUT>/usr/etc/biod 4</USERINPUT>
</CODE>
<PARAGRAPH>If <INDEXTARGET ID="nfsch624"><!-- POSTPROCESSDATA: nfsch624|failure:of network --><INDEXTARGET ID="nfsch625"><!-- POSTPROCESSDATA: nfsch625|retransmission rates --><ITALICS>biod</ITALICS> is running, check your network connection. The <COMMAND>netstat</COMMAND> command <USERINPUT>netstat&nbsp;-i</USERINPUT> reports errors and conditions that may help you determine why packets are being dropped. A packet is a unit of transmission sent across the network. Also, you can use <USERINPUT>nfsstat&nbsp;-c</USERINPUT> to tell if the client or server is retransmitting a lot. A retransmission rate of 5% is considered high. Excessive retransmission usually indicates a bad network controller board, a bad network transceiver, a mismatch between board and transceiver, a mismatch between your network controller board and the server's board, or any problem or congestion on the network that causes packet loss.</PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Failure to Access Remote Devices</TITLE><PARAGRAPH>You can not use NFS to mount a remote character or block device (that is, a remote tape drive or similar peripheral). <INDEXTARGET ID="nfsch626"><!-- POSTPROCESSDATA: nfsch626|remote devices --></PARAGRAPH>
</SECTION2>
</SECTION1>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="92032">Troubleshooting automount</TITLE><PARAGRAPH>This section presents a detailed explanation of how <INDEXTARGET ID="nfsch627"><!-- POSTPROCESSDATA: nfsch627|automatic mounters:process description --><COMMAND>automount</COMMAND> works that can help you with troubleshooting <COMMAND>automount</COMMAND> operation. </PARAGRAPH>
<PARAGRAPH>There are two distinct stages in <COMMAND>automount</COMMAND>'s actions: the initial stage, system startup, when <COMMAND>/etc/init.d/network</COMMAND> starts automount; and the mounting stage, when a user tries to access a file or directory on a remote system. These two stages, and the effect of map type (direct or indirect) on automounting behavior are described below.</PARAGRAPH>
<SECTION2 LBL="" HELPID = ""><TITLE>Role of automount in System Startup</TITLE><PARAGRAPH>At the initial stage, when <INDEXTARGET ID="nfsch628"><!-- POSTPROCESSDATA: nfsch628|automatic mounters:at system startup --><INDEXTARGET ID="nfsch629"><!-- POSTPROCESSDATA: nfsch629|<ITALICS>/etc/init.d/network</ITALICS> script --><INDEXTARGET ID="nfsch630"><!-- POSTPROCESSDATA: nfsch630|<ITALICS>automount</ITALICS> command:at system startup --><INDEXTARGET ID="nfsch631"><!-- POSTPROCESSDATA: nfsch631|file handle --><INDEXTARGET ID="nfsch632"><!-- POSTPROCESSDATA: nfsch632|portmapper --><COMMAND>/etc/init.d/network</COMMAND> invokes <COMMAND>automount</COMMAND>, it opens a user datagram protocol (UDP) socket and registers it with the portmapper service as an NFS server port. It then starts a server daemon that listens for NFS requests on the socket. The parent process proceeds to mount the daemon at its mount points within the filesystem (as specified by the maps). Through the <COMMAND>mount</COMMAND> system call, it passes the server daemon's port number and an NFS <ITALICS>file handle</ITALICS> that is unique to each mount point. The arguments to the mount system call vary according to the kind of file system. For NFS file systems, the call is:</PARAGRAPH>
<CODE>
mount ("nfs", "/usr", &amp;<VARIABLE>nfs_args</VARIABLE>);
</CODE>
<PARAGRAPH>where <VARIABLE>nfs_args</VARIABLE> contains the network address for the NFS server. By having the network address in <VARIABLE>nfs_args</VARIABLE> refer to the local process (the <COMMAND>automountd</COMMAND> daemon),<COMMAND>&space;automount</COMMAND> causes the kernel to treat it as if it were an NFS server. Once the parent process completes its calls to <COMMAND>mount</COMMAND>, it exits, leaving the automount daemon to serve its mount points.</PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Daemon Action in Mounting Process</TITLE><PARAGRAPH>In the second stage, when the user actually requests access to a remote file hierarchy, the daemon intercepts the kernel NFS request and looks up the name in the map associated with the directory.</PARAGRAPH>
<PARAGRAPH>Taking the location (<INDEXTARGET ID="nfsch633"><!-- POSTPROCESSDATA: nfsch633|automatic mounters:symbolic links --><INDEXTARGET ID="nfsch634"><!-- POSTPROCESSDATA: nfsch634|<ITALICS>/tmp_mnt</ITALICS> directory --><ITALICS>server:pathname</ITALICS>) of the remote filesystem from the map, the daemon then mounts the remote filesystem under the directory <FILENAME>/tmp_mnt</FILENAME>. It answers the kernel, saying it is a symbolic link. The kernel sends an NFS READLINK request, and the automounter returns a symbolic link to the real mount point under <FILENAME>/tmp_mnt</FILENAME>.</PARAGRAPH>
</SECTION2>
<SECTION2 LBL="" HELPID = ""><TITLE>Effect of automount Map Types</TITLE><PARAGRAPH>The behavior of the automounter is affected by whether the name is found in a direct or an indirect map. If the name is found in a direct map, the automounter emulates a symbolic link, as stated above. It responds as if a symbolic link exists at its mount point. In response to a GETATTR, it describes itself as a symbolic link. When the kernel follows up with a READLINK, it returns a path to the <INDEXTARGET ID="nfsch635"><!-- POSTPROCESSDATA: nfsch635|automatic mounters:map types --><ITALICS>real</ITALICS> mount point for the remote hierarchy in <FILENAME>/tmp_mnt</FILENAME>.</PARAGRAPH>
<PARAGRAPH>If, on the other hand, the name is found in an indirect map, the automounter emulates a directory of symbolic links. It describes itself as a directory. In response to a READLINK, it returns a path to the mount point in <FILENAME>/tmp_mnt</FILENAME>, and a <COMMAND>readdir </COMMAND>of the automounter's mount point returns a list of the entries that are currently mounted.</PARAGRAPH>
<PARAGRAPH>Whether the map is direct or indirect, if the file hierarchy is already mounted and the symbolic link has been read recently, the cached symbolic link is returned immediately. Since the automounter is on the same system, the response is much faster than a READLINK to a remote NFS server. On the other hand, if the file hierarchy is not mounted, a small delay occurs while the mounting takes place.</PARAGRAPH>
</SECTION2>
</SECTION1>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="52624">Troubleshooting autofs</TITLE><PARAGRAPH>The <COMMAND>autofs</COMMAND> process is similar to the <COMMAND>automount</COMMAND> process, described in <XREF IDREF="92032" TYPE="TITLE">&ldquo;Troubleshooting automount&rdquo;</XREF> with the following exceptions:</PARAGRAPH>
<BULLETLIST><BULLET><PARAGRAPH><COMMAND>autofs</COMMAND> uses the <COMMAND>autofsd</COMMAND> daemon for mounting and unmounting.</PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH>In-place mounting is used instead of symbolic links (the <FILENAME>/tmp_mnt</FILENAME> links with <FILENAME>/hosts</FILENAME> are not used).</PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><COMMAND>autofs</COMMAND> accepts dynamic configuration changes; there is no need to restart <COMMAND>autofsd.</COMMAND></PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><COMMAND>autofs</COMMAND> requires an <FILENAME>/etc/auto_master</FILENAME> file.</PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH><COMMAND>autofs</COMMAND> uses the LoFS (loopback file system) to access local files.</PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH>To record who is requesting bad mounts in the log file, set the <VARIABLE>autofs_logging</VARIABLE> variable of the <COMMAND>systune</COMMAND> option to <SCREENDISPLAY>autofs_logging=</SCREENDISPLAY><USERINPUT>1</USERINPUT>.</PARAGRAPH>
</BULLET>
</BULLETLIST>
</SECTION1>
<SECTION1 LBL="" HELPID = ""><TITLE><XREFTARGET ID="29475">Troubleshooting CacheFS</TITLE><PARAGRAPH>A common error message that can occur during a mount is <INDEXTARGET ID="nfsch636"><!-- POSTPROCESSDATA: nfsch636|CacheFS:troubleshootingtroubleshooting CacheFS --><SCREENDISPLAY>No space left on device</SCREENDISPLAY>. The most likely cause of this error is inappropriate allocation parameters for the cache. The following example shows this error for a CacheFS client machine named <ITALICS>nabokov</ITALICS>, caching data from a server neteng. One mount has been performed successfully for the cache <FILENAME>/cache</FILENAME>. A second mount was attempted and returned the error message <SCREENDISPLAY>No space left on device</SCREENDISPLAY>.  </PARAGRAPH>
<PARAGRAPH>The <COMMAND>cfsadmin -l</COMMAND> command returned the following:</PARAGRAPH>
<CODE>
&space;   cfsadmin: list cache FS information
&space;  Version        2   4  50
&space;  maxblocks     90% (1745743 blocks)
&space;   hiblocks     85% (1648757 blocks)
&space;  lowblocks     75% (1454786 blocks)
&space;  maxfiles      90% (188570 files)
&space;   hifiles      85% (178094 files)
&space;  lowfiles      75% (157142 files)
&space; neteng:_old-root-6.2_usr_local_lib:_usr_local_lib
&space; neteng:_usr_annex:_usr_annex
&space; bitbucket:_b_jmy:_usr_people_jmy_work
&space; neteng:_old-root-6.2_usr_local_bin:_usr_local_bin
</CODE>
<PARAGRAPH>The <COMMAND>df</COMMAND> command reported the usage statistics for <FILENAME>/cache</FILENAME> on nabokov. The following shows the <COMMAND>df</COMMAND> command and its returned information:</PARAGRAPH>
<CODE>
<USERINPUT>df -i /cache</USERINPUT>&space;
Filesystem  Type  blocks   use      avail   %use  iuse   ifree   %iuse  Mounted&lbreak;/dev/root   xfs   1939714  1651288  288426  85%   18120  191402  9%     /
</CODE>
<PARAGRAPH>If any files or blocks are allocated, CacheFS uses <CMDLINEOPT>hifiles</CMDLINEOPT> and <CMDLINEOPT>hiblocks</CMDLINEOPT> to determine whether to perform an allocation or fail with the error <SCREENDISPLAY>ENOSPC</SCREENDISPLAY>. CacheFS fails an allocation if the usage on the front file system is higher than <CMDLINEOPT>hiblocks</CMDLINEOPT> or <CMDLINEOPT>hifiles</CMDLINEOPT>, whichever is appropriate for the allocation being done. In this example, the <CMDLINEOPT>hifiles</CMDLINEOPT> value is 178094, but only 18120 files are in use. The <CMDLINEOPT>hiblocks</CMDLINEOPT> value is 103047 (8K blocks) or 1648752 512-byte blocks. The <COMMAND>df</COMMAND> output shows the total usage on the front file system is 1651288 512-byte blocks. This is larger than the threshold, so further block allocations fail.</PARAGRAPH>
<PARAGRAPH>The possible resolutions for the error are:</PARAGRAPH>
<BULLETLIST><BULLET><PARAGRAPH>Use <COMMAND>cfsadmin</COMMAND> to increase <CMDLINEOPT>hiblocks</CMDLINEOPT>. Increasing <CMDLINEOPT>hiblocks</CMDLINEOPT> should be effective since<FILENAME>&space;/dev/root</FILENAME> is already 85% allocated.</PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH>Remove unnecessary files from <FILENAME>/dev/root</FILENAME>. At least 2536 512-byte blocks of data need to be removed; removing more makes the cache more useful. At the current level of utilization, CacheFS needs to throw away many files to allow room for the new ones.</PARAGRAPH>
</BULLET>
<BULLET><PARAGRAPH>Use a separate disk partition for <FILENAME>/cache</FILENAME>.</PARAGRAPH>
</BULLET>
</BULLETLIST>
</SECTION1>
</CHAPTER>
